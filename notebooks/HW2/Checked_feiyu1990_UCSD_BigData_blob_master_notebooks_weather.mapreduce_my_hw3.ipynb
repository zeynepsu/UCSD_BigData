{
 "metadata": {
  "name": "",
  "signature": "sha256:de973f423cbb933160cb86b00247b4149fab54c28203372c69bf5b1758ba23e0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "PCA"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###First, in EMR do PCA for (Tmin, Tmax) of stations in each area."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sklearn as sk\n",
      "print 'pandas version: ',pd.__version__\n",
      "print 'numpy version:',np.__version__\n",
      "print 'sklearn version:',sk.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "home_dir='/home/ubuntu/UCSD_BigData'\n",
      "sys.path.append(home_dir+'/utils')\n",
      "from find_waiting_flow import *\n",
      "from AWS_keypair_management import *\n",
      "import pickle\n",
      "Creds= pickle.load(open('/home/ubuntu/Vault/Creds.pkl','rb'))\n",
      "print Creds.keys()\n",
      "print Creds['mrjob'].keys()\n",
      "pair=Creds['mrjob']\n",
      "key_id=pair['key_id']\n",
      "secret_key=pair['secret_key']\n",
      "ID=pair['ID']\n",
      "print ID,key_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_weather_PCA.py\n",
      "#import collections\n",
      "#Codes = collections.defaultdict(lambda: -1,Codes)\n",
      "import sys\n",
      "import cPickle\n",
      "Dict = cPickle.load( open( \"stations_with_minmax.pkl\", \"rb\" ) )\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re,pickle,base64,zlib\n",
      "from sys import stderr\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.decomposition import PCA\n",
      "\n",
      "def my_pca(X,n):\n",
      "    pca = PCA(n_components=n, whiten=True)\n",
      "    pca.fit(X)\n",
      "    sum1 = 0\n",
      "    for i in range(n):\n",
      "        sum1 = sum1 + pca.explained_variance_ratio_[i]\n",
      "        if sum1 > 0.99:\n",
      "            break\n",
      "    return i,pca.components_\n",
      "\n",
      "class MR_Weather_pca(MRJob):\n",
      "    def my_mapper1(self, _, line):\n",
      "        self.increment_counter('MrJob Counters','my_mapper1',1)\n",
      "        elements=line.split(',')\n",
      "        if elements[1]=='TMAX' or elements[1]=='TMIN':\n",
      "            ndays = sum([e!='' for e in elements[3:]])\n",
      "            measure = 1\n",
      "            yield (elements[0],elements[2]), (measure,ndays,elements[3:])\n",
      "            \n",
      "    def my_reducer1(self, key, measures):\n",
      "        self.increment_counter('MrJob Counters','my_reducer1',1)\n",
      "        sum1 = 0; sum2 = 0; min_max = []\n",
      "        for nmeasure,ndays,measure in measures:\n",
      "            sum1 = sum1 + nmeasure; sum2 = sum2 + ndays; min_max = min_max + measure\n",
      "        if sum1 == 2 and sum2>150:\n",
      "            yield key, (Dict[key[0]],min_max)\n",
      "            \n",
      "    def my_mapper2(self, key, measures):\n",
      "        self.increment_counter('MrJob Counters','my_mapper2',1)\n",
      "        value = []\n",
      "        for i in measures[1]:\n",
      "            if i == '':\n",
      "                value.append(np.nan)\n",
      "            else:\n",
      "                value.append(float(i))\n",
      "        filled = pd.Series(value);filled = filled.interpolate();filled = filled.fillna(filled.mean())\n",
      "        yield measures[0], list(filled)\n",
      "    \n",
      "    def my_reducer2(self, area, measures):\n",
      "        self.increment_counter('MrJob Counters','my_reducer2',1)\n",
      "        data = list(measures)\n",
      "        data = np.array(data)\n",
      "        n,eigenvectors = my_pca(data, data.shape[1])\n",
      "        yield area, n\n",
      "    def steps(self):\n",
      "        return [self.mr(mapper=self.my_mapper1, reducer=self.my_reducer1),\n",
      "                self.mr(mapper=self.my_mapper2,reducer=self.my_reducer2)]\n",
      "if __name__ == '__main__':\n",
      "    MR_Weather_pca.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting mr_weather_PCA.py\n"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_data='/home/ubuntu/UCSD_BigData/data/weather/ALL.head.csv'\n",
      "!python mr_weather_PCA.py $local_data > PCA_counts_local"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n",
        "creating tmp directory /tmp/mr_weather_PCA.ubuntu.20140527.043145.514175\r\n",
        "writing to /tmp/mr_weather_PCA.ubuntu.20140527.043145.514175/step-0-mapper_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  MrJob Counters:\r\n",
        "    my_mapper1: 999\r\n",
        "writing to /tmp/mr_weather_PCA.ubuntu.20140527.043145.514175/step-0-mapper-sorted\r\n",
        "> sort /tmp/mr_weather_PCA.ubuntu.20140527.043145.514175/step-0-mapper_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "writing to /tmp/mr_weather_PCA.ubuntu.20140527.043145.514175/step-0-reducer_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  MrJob Counters:\r\n",
        "    my_mapper1: 999\r\n",
        "    my_reducer1: 123\r\n",
        "writing to /tmp/mr_weather_PCA.ubuntu.20140527.043145.514175/step-1-mapper_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 2:\r\n",
        "  MrJob Counters:\r\n",
        "    my_mapper2: 104\r\n",
        "writing to /tmp/mr_weather_PCA.ubuntu.20140527.043145.514175/step-1-mapper-sorted\r\n",
        "> sort /tmp/mr_weather_PCA.ubuntu.20140527.043145.514175/step-1-mapper_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "writing to /tmp/mr_weather_PCA.ubuntu.20140527.043145.514175/step-1-reducer_part-00000\r\n",
        "Counters from step 2:\r\n",
        "  MrJob Counters:\r\n",
        "    my_mapper2: 104\r\n",
        "    my_reducer2: 3\r\n",
        "Moving /tmp/mr_weather_PCA.ubuntu.20140527.043145.514175/step-1-reducer_part-00000 -> /tmp/mr_weather_PCA.ubuntu.20140527.043145.514175/output/part-00000\r\n",
        "Streaming final output from /tmp/mr_weather_PCA.ubuntu.20140527.043145.514175/output\r\n",
        "removing tmp directory /tmp/mr_weather_PCA.ubuntu.20140527.043145.514175\r\n"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First debug on the local dataset. The result is as follows. The function returns each area code and its explanation length for 99%."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat PCA_counts_local"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "158.0\t36\r\n",
        "168.0\t17\r\n",
        "4.0\t40\r\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#job_flow_id=find_waiting_flow(key_id,secret_key)\n",
      "#print job_flow_id\n",
      "#job_flow_id = 'j-2KCJE554SGITB'\n",
      "!python mr_weather_PCA.py -r emr --emr-job-flow-id j-6T8VIKMY8RHX --file stations_with_minmax.pkl hdfs:/weather/weather.csv > PCA_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating new scratch bucket mrjob-f2646beb6446970f\r\n",
        "using s3://mrjob-f2646beb6446970f/tmp/ as our scratch dir on S3\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /tmp/mr_weather_PCA.ubuntu.20140527.043153.694408\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating S3 bucket 'mrjob-f2646beb6446970f' to use as scratch space\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://mrjob-f2646beb6446970f/tmp/mr_weather_PCA.ubuntu.20140527.043153.694408/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding our job to existing job flow j-6T8VIKMY8RHX\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 30.8s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 61.5s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>0dfd3ea6-e558-11e3-b332-21d671b574dc</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>19ee09a1-e558-11e3-8362-0f887c06ae20</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 30.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 142.3s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>3e201791-e558-11e3-8362-0f887c06ae20</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>4a1093f4-e558-11e3-8362-0f887c06ae20</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 30.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>5bf7b583-e558-11e3-955c-1fb30f4201c5</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 45.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>76d378ce-e558-11e3-b332-21d671b574dc</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 67.5 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 335.7s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 1 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 366.5s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 1 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>c3cd96d5-e558-11e3-8c68-dfb11431f3fe</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 417.3s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 1 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 448.1s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 1 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 478.8s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 1 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 509.6s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>1916040d-e559-11e3-abd6-21155152508b</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 560.4s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 591.2s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 621.9s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 652.7s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 683.5s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 714.1s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 744.8s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 775.5s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>b7912758-e559-11e3-a13b-cf267f9d23d6</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 826.2s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 856.9s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 887.6s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>fa6b8fcd-e559-11e3-abd6-21155152508b</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 938.4s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 969.0s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 999.8s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1030.4s ago, status RUNNING: Running step (mr_weather_PCA.ubuntu.20140527.043153.694408: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job completed.\r\n",
        "Running time was 837.0s (not counting time spent waiting for the EC2 instances)\r\n",
        "ec2_key_pair_file not specified, going to S3\r\n",
        "Fetching counters from S3...\r\n",
        "Waiting 5.0s for S3 eventual consistency\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters may not have been uploaded to S3 yet. Try again in 5 minutes with: mrjob fetch-logs --counters j-6T8VIKMY8RHX\r\n",
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "Counters from step 2:\r\n",
        "  (no counters found)\r\n",
        "Streaming final output from s3://mrjob-f2646beb6446970f/tmp/mr_weather_PCA.ubuntu.20140527.043153.694408/output/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "removing tmp directory /tmp/mr_weather_PCA.ubuntu.20140527.043153.694408\r\n",
        "Removing all files in s3://mrjob-f2646beb6446970f/tmp/mr_weather_PCA.ubuntu.20140527.043153.694408/\r\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -10 PCA_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "106.0\t436\r\n",
        "117.0\t432\r\n",
        "120.0\t475\r\n",
        "128.0\t392\r\n",
        "131.0\t411\r\n",
        "139.0\t441\r\n",
        "142.0\t434\r\n",
        "153.0\t471\r\n",
        "16.0\t387\r\n",
        "164.0\t418\r\n"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Yoav:** You did all of this work to find the PCA vectors. Why do you not keep the resulting eigenvectors and eigenvalues? (I would also keep the resulting covariance matrix to use for merge decision."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "length = []; area=[]\n",
      "for line in open('PCA_results','r').readlines():\n",
      "    line=line.split()\n",
      "    length.append(numpy.int(line[1]))\n",
      "    temp_area = numpy.float(line[0])\n",
      "    area.append(int(temp_area))\n",
      "print mean(length)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "428.359375\n"
       ]
      }
     ],
     "prompt_number": 133
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As is shown above, the average explanation length for 99% is ~428.\n",
      "\n",
      "**Yoav:** 99% is probably too high of a threshold. I would look for a threhold that gives around 10 eigen-vectors."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "D = pd.DataFrame({'area': area, 'length': length})\n",
      "D.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>area</th>\n",
        "      <th>length</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 106</td>\n",
        "      <td> 436</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 117</td>\n",
        "      <td> 432</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 120</td>\n",
        "      <td> 475</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 128</td>\n",
        "      <td> 392</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 131</td>\n",
        "      <td> 411</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 134,
       "text": [
        "   area  length\n",
        "0   106     436\n",
        "1   117     432\n",
        "2   120     475\n",
        "3   128     392\n",
        "4   131     411\n",
        "\n",
        "[5 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "plt.figure()\n",
      "D['length'].hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 108,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x6102fd0>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD9CAYAAABdoNd6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x6102cd0>"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The distribution of description length is more clearly shown in the histogram above."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Second, merge the neighboring nodes to get lower description length."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, try one iteration of merging. The area code I use is from 0-255, and neighboring area codes correspond to neighbouring areas on the globe. So the candidates of merging can be expressed as (0,1),(2,3), ... ,(254,255). The new area dictionary is easily obtained:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_Dict = {}\n",
      "for i in Dict:\n",
      "    new_Dict[i] = np.int(np.floor(Dict[i]/2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(new_Dict, open('stations_new_dictionary.pkl', 'w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 122
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then use the new area dictionary to run PCA."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_weather_PCA_merge.py\n",
      "#import collections\n",
      "#Codes = collections.defaultdict(lambda: -1,Codes)\n",
      "import sys\n",
      "import cPickle\n",
      "Dict = cPickle.load( open( \"stations_new_dictionary.pkl\", \"rb\" ) )\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re,pickle,base64,zlib\n",
      "from sys import stderr\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.decomposition import PCA\n",
      "\n",
      "def my_pca(X,n):\n",
      "    pca = PCA(n_components=n, whiten=True)\n",
      "    pca.fit(X)\n",
      "    sum1 = 0\n",
      "    for i in range(n):\n",
      "        sum1 = sum1 + pca.explained_variance_ratio_[i]\n",
      "        if sum1 > 0.99:\n",
      "            break\n",
      "    return i,pca.components_\n",
      "\n",
      "class MR_Weather_pca(MRJob):\n",
      "    def my_mapper1(self, _, line):\n",
      "        self.increment_counter('MrJob Counters','my_mapper1',1)\n",
      "        elements=line.split(',')\n",
      "        if elements[1]=='TMAX' or elements[1]=='TMIN':\n",
      "            ndays = sum([e!='' for e in elements[3:]])\n",
      "            measure = 1\n",
      "            yield (elements[0],elements[2]), (measure,ndays,elements[3:])\n",
      "            \n",
      "    def my_reducer1(self, key, measures):\n",
      "        self.increment_counter('MrJob Counters','my_reducer1',1)\n",
      "        sum1 = 0; sum2 = 0; min_max = []\n",
      "        for nmeasure,ndays,measure in measures:\n",
      "            sum1 = sum1 + nmeasure; sum2 = sum2 + ndays; min_max = min_max + measure\n",
      "        if sum1 == 2 and sum2>150:\n",
      "            yield key, (Dict[key[0]],min_max)\n",
      "            \n",
      "    def my_mapper2(self, key, measures):\n",
      "        self.increment_counter('MrJob Counters','my_mapper2',1)\n",
      "        value = []\n",
      "        for i in measures[1]:\n",
      "            if i == '':\n",
      "                value.append(np.nan)\n",
      "            else:\n",
      "                value.append(float(i))\n",
      "        filled = pd.Series(value);filled = filled.interpolate();filled = filled.fillna(filled.mean())\n",
      "        yield measures[0], list(filled)\n",
      "    \n",
      "    def my_reducer2(self, area, measures):\n",
      "        self.increment_counter('MrJob Counters','my_reducer2',1)\n",
      "        data = list(measures)\n",
      "        data = np.array(data)\n",
      "        n,eigenvectors = my_pca(data, data.shape[1])\n",
      "        yield area, n\n",
      "    def steps(self):\n",
      "        return [self.mr(mapper=self.my_mapper1, reducer=self.my_reducer1),\n",
      "                self.mr(mapper=self.my_mapper2,reducer=self.my_reducer2)]\n",
      "if __name__ == '__main__':\n",
      "    MR_Weather_pca.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing mr_weather_PCA_merge.py\n"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_weather_PCA_merge.py -r emr --emr-job-flow-id j-LTOJMJ14G840 --file stations_new_dictionary.pkl hdfs:/weather/weather.csv > PCA_merged_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating new scratch bucket mrjob-909373fc37c21513\r\n",
        "using s3://mrjob-909373fc37c21513/tmp/ as our scratch dir on S3\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /tmp/mr_weather_PCA_merge.ubuntu.20140527.060948.219871\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating S3 bucket 'mrjob-909373fc37c21513' to use as scratch space\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://mrjob-909373fc37c21513/tmp/mr_weather_PCA_merge.ubuntu.20140527.060948.219871/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding our job to existing job flow j-LTOJMJ14G840\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 31.2s ago, status RUNNING: Running step (mr_weather_PCA_merge.ubuntu.20140527.060948.219871: Step 1 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 62.6s ago, status RUNNING: Running step (mr_weather_PCA_merge.ubuntu.20140527.060948.219871: Step 1 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 93.7s ago, status RUNNING: Running step (mr_weather_PCA_merge.ubuntu.20140527.060948.219871: Step 1 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>cf6be8ad-e565-11e3-aa87-172672d76e00</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>db5c3f05-e565-11e3-955c-1fb30f4201c5</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 30.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>ed44232d-e565-11e3-9077-5114ea9dc6a3</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 45.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>081f49e1-e566-11e3-955c-1fb30f4201c5</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 67.5 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 287.8s ago, status RUNNING: Running step (mr_weather_PCA_merge.ubuntu.20140527.060948.219871: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 319.1s ago, status RUNNING: Running step (mr_weather_PCA_merge.ubuntu.20140527.060948.219871: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>55c8e198-e566-11e3-aa87-172672d76e00</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 370.4s ago, status RUNNING: Running step (mr_weather_PCA_merge.ubuntu.20140527.060948.219871: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>745ccb19-e566-11e3-aa87-172672d76e00</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>804d6f90-e566-11e3-aa87-172672d76e00</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 30.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 451.6s ago, status RUNNING: Running step (mr_weather_PCA_merge.ubuntu.20140527.060948.219871: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 483.0s ago, status RUNNING: Running step (mr_weather_PCA_merge.ubuntu.20140527.060948.219871: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 514.3s ago, status RUNNING: Running step (mr_weather_PCA_merge.ubuntu.20140527.060948.219871: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 545.4s ago, status RUNNING: Running step (mr_weather_PCA_merge.ubuntu.20140527.060948.219871: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>dcb21521-e566-11e3-aa87-172672d76e00</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 596.7s ago, status RUNNING: Running step (mr_weather_PCA_merge.ubuntu.20140527.060948.219871: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 628.0s ago, status RUNNING: Running step (mr_weather_PCA_merge.ubuntu.20140527.060948.219871: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 659.2s ago, status RUNNING: Running step (mr_weather_PCA_merge.ubuntu.20140527.060948.219871: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 690.6s ago, status RUNNING: Running step (mr_weather_PCA_merge.ubuntu.20140527.060948.219871: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 721.9s ago, status RUNNING: Running step (mr_weather_PCA_merge.ubuntu.20140527.060948.219871: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 753.2s ago, status RUNNING: Running step (mr_weather_PCA_merge.ubuntu.20140527.060948.219871: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 784.4s ago, status RUNNING: Running step (mr_weather_PCA_merge.ubuntu.20140527.060948.219871: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>6b1fdfc9-e567-11e3-a94d-e755ea6b183b</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>77103627-e567-11e3-a94d-e755ea6b183b</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 30.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job completed.\r\n",
        "Running time was 804.0s (not counting time spent waiting for the EC2 instances)\r\n",
        "ec2_key_pair_file not specified, going to S3\r\n",
        "Fetching counters from S3...\r\n",
        "Waiting 5.0s for S3 eventual consistency\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>8cf0083f-e567-11e3-abd6-21155152508b</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>98e0acb0-e567-11e3-abd6-21155152508b</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 30.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>aac8df1c-e567-11e3-abd6-21155152508b</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 45.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>c5a405e2-e567-11e3-abd6-21155152508b</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 67.5 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters may not have been uploaded to S3 yet. Try again in 5 minutes with: mrjob fetch-logs --counters j-LTOJMJ14G840\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "Counters from step 2:\r\n",
        "  (no counters found)\r\n",
        "Streaming final output from s3://mrjob-909373fc37c21513/tmp/mr_weather_PCA_merge.ubuntu.20140527.060948.219871/output/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "removing tmp directory /tmp/mr_weather_PCA_merge.ubuntu.20140527.060948.219871\r\n",
        "Removing all files in s3://mrjob-909373fc37c21513/tmp/mr_weather_PCA_merge.ubuntu.20140527.060948.219871/\r\n"
       ]
      }
     ],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "length_merge = []; area_merge=[]\n",
      "for line in open('PCA_merged_results','r').readlines():\n",
      "    line=line.split()\n",
      "    length_merge.append(numpy.int(line[1]))\n",
      "    temp_area = numpy.float(line[0])\n",
      "    area_merge.append(int(temp_area))\n",
      "print mean(length_merge)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "462.890625\n"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we have the descript length of PCA before and after merge. Then use the criterion described in  http://seed.ucsd.edu/mediawiki/index.php/BigDataHW2#Suggested_Steps to see whether each merge should or shoulndn't happen."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def merge_criterion(n1,k1,n2,k2,k3):\n",
      "    n3 = n1+n2\n",
      "    left = n1*k1+(k1+1)*(2*365)+n2*k2+(k2+1)*(2*365)\n",
      "    right = n3*k3+(k3+1)*(2*365)\n",
      "    merge = left>right\n",
      "    return merge"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "before_merge = numpy.asarray([area, length])\n",
      "after_merge = numpy.asarray([area_merge, length_merge])\n",
      "before_merge =  before_merge[:,np.argsort(before_merge[0,:])].transpose()\n",
      "after_merge =  after_merge[:,np.argsort(after_merge[0,:])].transpose()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "after_merge.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 149,
       "text": [
        "(128, 2)"
       ]
      }
     ],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in xrange(after_merge.shape[0]):\n",
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Summary ###\n",
      "You did some nice work on both the weighting and the partitioning. In the PCA section you seem not to care about the actual PCA Vectors. You did not get to do anything meaningful in terms of merging.\n",
      "\n",
      "**Grade:** 85"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}