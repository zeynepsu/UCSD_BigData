{
 "metadata": {
  "name": "",
  "signature": "sha256:dcfdc0b28c53250cbba625723edb5be270e15b0f10146deb2f05e0aa3a681604"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color = 'blue'> Import Modules </font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os,sys,re,pickle, sklearn, numpy, re, base64, zlib\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "home_dir='/home/ubuntu/UCSD_BigData'\n",
      "data_dir=home_dir+'/data/weather'\n",
      "!ls $data_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ALL.head.csv\t  ghcnd-stations_buffered.txt  SAMPLE_TMAX.csv\r\n",
        "data-source.txt   ghcnd-stations.txt\t       SAMPLE_TMAX.csv.old.gz\r\n",
        "ghcnd-readme.txt  ghcnd-version.txt\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f1 = open('partition_tree.pkl', 'rb') \n",
      "(Data_Stations, valid_years, group_neighbours, group2id) = pickle.load(f1) \n",
      "f1.close() \n",
      "\n",
      "num_stations = Data_Stations.shape[0]\n",
      "stations = np.array(Data_Stations.index)\n",
      "lons = np.array(Data_Stations.ix[:,'longitude'])\n",
      "lats = np.array(Data_Stations.ix[:,'latitude'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f2 = open('partition_matrices_data.pkl', 'rb') \n",
      "matrix_data_orig = pickle.load(f2) \n",
      "f2.close() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#group_neighbours - stores all the current ids of the leaves \n",
      "cannot_merge = dict([(g, []) for g in group_neighbours.keys()]) #store the pairs which cannot be merged to avoid redundancy \n",
      "final_id = np.array([group2id[i] for i in Data_Stations['group_id']])\n",
      "matrix_data = matrix_data_orig.copy()\n",
      "neighbours = group_neighbours.copy()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color= 'blue'> Clustering with MDL \n",
      "<ul>\n",
      "<li>If P1 and P2 are neighbors, we check if MDL(P1+P2) < MDL(P1) + MDL(P2). If so, we merge P1 and P2. If not, we check other partitions.</li>\n",
      "<li>This is done till no merging is possible.</li>\n",
      "</ul>\n",
      " </font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def can_merge(l, r):\n",
      "    (outer1, mean1, l1) = matrix_data[str(l)]\n",
      "    (outer2, mean2, l2) = matrix_data[str(r)]\n",
      "    covar1 = outer1/l1 - np.outer(mean1,mean1)\n",
      "    covar2 = outer2/l2 - np.outer(mean2,mean2)\n",
      "    _, D1, _ = np.linalg.svd(covar1)\n",
      "    _, D2, _ = np.linalg.svd(covar2)\n",
      "    cum1 = cumsum(D1[:])/sum(D1)\n",
      "    cum2 = cumsum(D2[:])/sum(D2)\n",
      "    k1 = np.searchsorted(cum1, 0.99)\n",
      "    k2 = np.searchsorted(cum2, 0.99)\n",
      "    \n",
      "    l3 = l1 + l2\n",
      "    outer3 = outer1 + outer2\n",
      "    mean3 = (l1*mean1 + l2*mean2)/l3\n",
      "    covar3 = outer3/l3 - mean3\n",
      "    _, D3, _ = np.linalg.svd(covar3)\n",
      "    cum3 = cumsum(D3[:])/sum(D3)\n",
      "    k3 = np.searchsorted(cum3, 0.99)\n",
      "    \n",
      "    if( l1*k1+(k1+1)*(2*365) + l2*k2+(k2+1)*(2*365) >= l3*k3 + (k3+1)*(2*365)): #MDL criterion for merging\n",
      "        matrix_data[str(l)] = (outer3, mean3, l3)\n",
      "        del matrix_data[str(r)]\n",
      "        print 'merged'\n",
      "        return True\n",
      "    \n",
      "    return False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "while (True):\n",
      "    merged = False\n",
      "    \n",
      "    for g1 in neighbours.keys(): \n",
      "        for g2 in neighbours[g1]:\n",
      "\n",
      "            #print g1, g2\n",
      "\n",
      "            if(g1 in cannot_merge[g2]): \n",
      "                continue\n",
      "\n",
      "            if(can_merge(g1, g2)): \n",
      "                \n",
      "                neighbours[g1].pop(neighbours[g1].index(g2))\n",
      "                neighbours[g2].pop(neighbours[g2].index(g1))\n",
      "                \n",
      "                \n",
      "                neighbours[g1] =  neighbours[g1] + neighbours[g2]\n",
      "                            \n",
      "        \n",
      "                cannot_merge[g1] = []\n",
      "                final_id[final_id == g2] = g1\n",
      "                \n",
      "                for ng2 in neighbours[g2]:\n",
      "                    neighbours[ng2].pop(neighbours[ng2].index(g2))\n",
      "                    if not (g1 in neighbours[ng2]): \n",
      "                        neighbours[ng2].append(g1)\n",
      "                        \n",
      "                del neighbours[g2]\n",
      "                del cannot_merge[g2]\n",
      "\n",
      "                merged = True\n",
      "                break\n",
      "\n",
      "            else : \n",
      "                cannot_merge[g1].append(g2)\n",
      "                cannot_merge[g2].append(g1)\n",
      "        if(merged): break\n",
      "        \n",
      "    if(not merged): break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merged\n",
        "merged"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "merged"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "merged"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "merged"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyError",
       "evalue": "'388'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-10-5fd6eae1c5fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcan_merge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0mneighbours\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneighbours\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-9-2109e69c7583>\u001b[0m in \u001b[0;36mcan_merge\u001b[1;34m(l, r)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcan_merge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mouter1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mouter2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mcovar1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mouter1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0ml1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcovar2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mouter2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0ml2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyError\u001b[0m: '388'"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('final_group_id.pkl','wb')\n",
      "pickle.dump(final_id,f)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}