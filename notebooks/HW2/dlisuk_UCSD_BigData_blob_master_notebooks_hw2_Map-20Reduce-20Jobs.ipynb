{
 "metadata": {
  "name": "",
  "signature": "sha256:f4f8fb51342192b4ae6b6d359911173c748878d86fccee592b835203c6c2a694"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Map Reduce Jobs\n",
      "\n",
      "This notebook contains a series of map reduce jobs which produce output data that is analyzed in other notebooks.  Each job has a brief description and the notebook is organized roughly temporally. (**Yoav:** Temporally according to the order of the data, the order of your work flow? The chronological order in which you worked?).\n",
      "\n",
      "These jobs may take a long time, so it is recomended they not be run as part of grading."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#big data imports\n",
      "import sys\n",
      "home_dir='/home/ubuntu/UCSD_BigData'\n",
      "sys.path.append(home_dir+'/utils')\n",
      "from find_waiting_flow import *\n",
      "from AWS_keypair_management import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Setup for map reduce jobs\n",
      "import pickle\n",
      "Creds= pickle.load(open('/home/ubuntu/Vault/Creds.pkl','rb'))\n",
      "print Creds.keys()\n",
      "print Creds['mrjob'].keys()\n",
      "pair=Creds['mrjob']\n",
      "key_id=pair['key_id']\n",
      "secret_key=pair['secret_key']\n",
      "ID=pair['ID']\n",
      "print \"Logged in as: \" + ID\n",
      "\n",
      "job_flow_id=find_waiting_flow(key_id,secret_key)\n",
      "print \"Free job flow: \" + job_flow_id\n",
      "\n",
      "local_data='/home/ubuntu/UCSD_BigData/data/weather/ALL.head.csv'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This command is a security breach: the secret part of \n",
      "#!cat /home/ubuntu/.mrjob.conf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Exploratory Analysis\n",
      "\n",
      "These jobs relate to initial exploratory analysis I did"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_scripts/variable_counts.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "\n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "    def mapper(self, _, line):\n",
      "        try:\n",
      "            F=line.split(',')\n",
      "            if F[0]!='station':\n",
      "                station = F[0]\n",
      "                measure = F[1]\n",
      "                year    = int(F[2])\n",
      "                goodCount = 0\n",
      "                for x in F[3:]:\n",
      "                    try:\n",
      "                        float(x)\n",
      "                        goodCount += 1\n",
      "                    except Exception, e:\n",
      "                        None\n",
      "                yield (measure,1)\n",
      "                \n",
      "        except Exception, e:\n",
      "            yield ((\"error\",e), 1)\n",
      "            \n",
      "    def combiner(self, key, data):\n",
      "        if key[0] == \"error\":\n",
      "            yield (key,sum(data))\n",
      "        yield (key,sum(data))\n",
      "    def reducer(self, key, data):\n",
      "        if key[0] == \"error\":\n",
      "            yield (key,sum(data))\n",
      "        yield (key,sum(data))        \n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_scripts/variable_counts.py $local_data > mr_output/variable_counts.small\n",
      "!head mr_output/variable_counts.small"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "job_flow_id='j-2EFV3O64LF1U2'\n",
      "!python mr_scripts/variable_counts.py -r emr --emr-job-flow-id $job_flow_id hdfs:/weather/weather.csv > mr_output/variable_counts\n",
      "!head mr_output/variable_counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_scripts/good_counts.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "\n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "    def readNum(x):\n",
      "        try:\n",
      "            out = float(x)\n",
      "        except Exception, e:\n",
      "            out = None\n",
      "        finally:\n",
      "            return out\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        try:\n",
      "            F=line.split(',')\n",
      "            if F[0]!='station':\n",
      "                station = F[0]\n",
      "                measure = F[1]\n",
      "                year    = int(F[2])\n",
      "                goodCount = 0\n",
      "                for x in F[3:]:\n",
      "                    try:\n",
      "                        float(x)\n",
      "                        goodCount += 1\n",
      "                    except Exception, e:\n",
      "                        None\n",
      "                yield ((measure,year),(1,goodCount,goodCount*goodCount))\n",
      "                \n",
      "        except Exception, e:\n",
      "            yield ((\"error\",e), 1)\n",
      "            \n",
      "    def combiner(self, key, data):\n",
      "        if key[0] == \"error\":\n",
      "            yield (key,sum(data))\n",
      "        s_count = 0\n",
      "        g_count = 0\n",
      "        gs_count = 0\n",
      "        for s,g,gs in data:\n",
      "            s_count += s\n",
      "            g_count += g\n",
      "            gs_count += gs\n",
      "        yield (key,(s_count,g_count,gs_count))\n",
      "    def reducer(self, key, data):\n",
      "        if key[0] == \"error\":\n",
      "            yield (key,sum(data))\n",
      "        s_count = 0\n",
      "        g_count = 0\n",
      "        gs_count = 0\n",
      "        for s,g,gs in data:\n",
      "            s_count += s\n",
      "            g_count += g\n",
      "            gs_count += gs\n",
      "        yield (key,(s_count,g_count,gs_count))\n",
      "        \n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_scripts/good_counts.py $local_data > mr_output/good_counts.small\n",
      "!head mr_output/good_counts.small"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_scripts/good_counts.py -r emr --emr-job-flow-id $job_flow_id hdfs:/weather/weather.csv > mr_output/good_counts\n",
      "!head mr_output/good_counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_scripts/geo_bins.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "\n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "import gzip\n",
      "import cPickle\n",
      "from sets import Set \n",
      "import os\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "    def configure_options(self):\n",
      "        super(MRWeather,self).configure_options()\n",
      "        self.add_file_option('--stations')\n",
      " \n",
      "\n",
      "    def mapper_init(self):\n",
      "        f = gzip.open( self.options.stations, \"rb\" )\n",
      "        pickleFile = cPickle.Unpickler( f )\n",
      "        self.stations = pickleFile.load()[['latitude','longitude','elevation']]\n",
      "        f.close()\n",
      "        self.keep = Set(['PRCP','TMIN','TMAX','SNOW','SNWD'])\n",
      "        \n",
      "    def mapper(self, _, line):\n",
      "        try:\n",
      "            F=line.split(',')\n",
      "            if F[0]!='station':\n",
      "                measure = F[1]\n",
      "                year    = int(F[2])\n",
      "                if measure in self.keep:# and year == 2012:\n",
      "                    station = F[0]\n",
      "                    stationInfo = self.stations.loc[station]\n",
      "                    lat = stationInfo['latitude']\n",
      "                    lat_bin = int(lat/10)*10+cmp(lat,0)*5\n",
      "                    lon = stationInfo['longitude']\n",
      "                    lon_bin = int(lon/10)*10+cmp(lon,0)*5\n",
      "                    goodCount = 0\n",
      "                    yield ((measure,lat_bin,lon_bin),1)\n",
      "                \n",
      "        except Exception, e:\n",
      "            yield ((\"error\",str(e)), 1)\n",
      "            \n",
      "    def combiner(self, key, data):\n",
      "        yield (key,sum(data))\n",
      "    def reducer(self, key, data):\n",
      "        yield (key,sum(data))\n",
      "        \n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_scripts/geo_bins.py --stations ./stations.pkl.gz  $local_data  > mr_output/geo_bins.small\n",
      "!head mr_output/geo_bins.small"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_scripts/geo_bins.py -r emr --emr-job-flow-id $job_flow_id --stations s3://Weather.GHNC/stations.pkl.gz hdfs:/weather/weather.csv > mr_output/geo_bins_all\n",
      "!head mr_output/geo_bins_all"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_scripts/geo_4meas.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "\n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "import gzip\n",
      "import cPickle\n",
      "from sets import Set \n",
      "import os\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "    def configure_options(self):\n",
      "        super(MRWeather,self).configure_options()\n",
      "        self.add_file_option('--stations')\n",
      " \n",
      "\n",
      "    def mapper_init(self):\n",
      "        f = gzip.open( self.options.stations, \"rb\" )\n",
      "        pickleFile = cPickle.Unpickler( f )\n",
      "        self.stations = pickleFile.load()[['latitude','longitude','elevation']]\n",
      "        f.close()\n",
      "        self.keep = Set(['PRCP','TMIN','TMAX','SNWD'])\n",
      "        self.meas = {'PRCP':0,'TMIN':1,'TMAX':2,'SNWD':3}\n",
      "        \n",
      "    def mapper(self, _, line):\n",
      "        try:\n",
      "            F=line.split(',')\n",
      "            if F[0]!='station':\n",
      "                station = F[0]\n",
      "                measure = F[1]\n",
      "                year    = int(F[2])\n",
      "                out = [0,0,0,0]\n",
      "                if measure in self.keep and year == 2012:\n",
      "                    stationInfo = self.stations.loc[station]\n",
      "                    lat = stationInfo['latitude']\n",
      "                    lat_bin = int(lat/10)*10+cmp(lat,0)*5\n",
      "                    lon = stationInfo['longitude']\n",
      "                    lon_bin = int(lon/10)*10+cmp(lon,0)*5\n",
      "                    out[self.meas[measure]]=1\n",
      "                    yield ((lat_bin,lon_bin),out)\n",
      "                \n",
      "        except Exception, e:\n",
      "            yield ((\"error\",str(e)), 1)\n",
      "            \n",
      "    def combiner(self, key, data):\n",
      "        out = [0,0,0,0]\n",
      "        for elem in data:\n",
      "            for i in range(len(elem)):\n",
      "                out[i]+=elem[i]\n",
      "        yield (key,out)\n",
      "    def reducer(self, key, data):\n",
      "        out = [0,0,0,0]\n",
      "        for elem in data:\n",
      "            for i in range(len(elem)):\n",
      "                out[i]+=elem[i]\n",
      "        yield (key,out)\n",
      "        \n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_scripts/geo_bins.py -r emr --emr-job-flow-id $job_flow_id \u2013no-output hdfs:/weather/weather.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_scripts/geo_4meas.py --stations ./stations.pkl.gz  $local_data  > mr_output/geo_4meas.small\n",
      "!head mr_output/geo_4meas.small"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_scripts/geo_4meas.py -r emr --emr-job-flow-id $job_flow_id --stations s3://Weather.GHNC/stations.pkl.gz hdfs:/weather/weather.csv > mr_output/geo_4meas\n",
      "!head mr_output/geo_4meas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_scripts/check_for_dupes.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "\n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "    def mapper(self, _, line):\n",
      "        try:\n",
      "            F=line.split(',')\n",
      "            if F[0]!='station':\n",
      "                station = F[0]\n",
      "                measure = F[1]\n",
      "                year    = F[2]\n",
      "                yield ((measure,station,year),1)\n",
      "                \n",
      "        except Exception, e:\n",
      "            yield ((\"error\",e), 1)\n",
      "            \n",
      "    def combiner(self, key, data):\n",
      "        if key[0] == \"error\":\n",
      "            yield (key,sum(data))\n",
      "        out = sum(data)\n",
      "        if out > 1:\n",
      "             self.increment_counter('Key Collision', str(key)) \n",
      "        yield (key,out)        \n",
      "    def reducer(self, key, data):\n",
      "        if key[0] == \"error\":\n",
      "            yield (key,sum(data))\n",
      "        out = sum(data)\n",
      "        if out > 1:\n",
      "             self.increment_counter('Key Collision', str(key)) \n",
      "        yield (key,out)        \n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_scripts/check_for_dupes.py -r emr --emr-job-flow-id $job_flow_id --no-output hdfs:/weather/weather.csv "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!mrjob fetch-logs --counters j-262J0JTFJIRLO "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_scripts/final_data_prep.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "\n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "import gzip\n",
      "import cPickle\n",
      "from sets import Set \n",
      "import os\n",
      "\n",
      "def readNum(x):\n",
      "    try:\n",
      "        out = float(x)\n",
      "    except Exception, e:\n",
      "        out = None\n",
      "    finally:\n",
      "        return out\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "    def configure_options(self):\n",
      "        super(MRWeather,self).configure_options()\n",
      "        self.add_file_option('--stations')\n",
      " \n",
      "\n",
      "    def mapper_init(self):\n",
      "        f = gzip.open( self.options.stations, \"rb\" )\n",
      "        pickleFile = cPickle.Unpickler( f )\n",
      "        self.stations = pickleFile.load()[['latitude','longitude','elevation']]\n",
      "        f.close()\n",
      "        self.keep = Set(['PRCP','TMIN','TMAX','SNWD'])\n",
      "        self.meas = {'PRCP':0,'TMIN':1,'TMAX':2,'SNWD':3}\n",
      "        \n",
      "        \n",
      "    def mapper(self, _, line):\n",
      "        try:\n",
      "            F=line.split(',')\n",
      "            if F[0]!='station':\n",
      "                station = F[0]\n",
      "                measure = F[1]\n",
      "                year    = int(F[2])\n",
      "                out = ([None]*366)*4\n",
      "                within = [False]*4\n",
      "                if measure in self.keep and year >= 1950:\n",
      "                    offset = 366*self.meas[measure]\n",
      "                    within[self.meas[measure]] = True\n",
      "                    goodCount = 0\n",
      "                    for elem in F[3:]:\n",
      "                        out[offset] = readNum(elem)\n",
      "                        if out[offset] != None:\n",
      "                            goodCount += 1\n",
      "                        offset += 1\n",
      "                    if goodCount > 50:\n",
      "                        yield ((station,year),(within,out))\n",
      "                \n",
      "        except Exception, e:\n",
      "            yield ((\"error\",str(e)), 1)\n",
      "            \n",
      "    def combiner(self, key, data):\n",
      "        out = ([None]*366)*4\n",
      "        within = [False]*4\n",
      "        for elem in data:\n",
      "            for i in range(4):\n",
      "                if elem[0][i]:\n",
      "                    within[i] = True\n",
      "            for i in range(len(elem[1])):\n",
      "                if(out[i] == None):\n",
      "                    out[i]=elem[1][i]\n",
      "        yield (key,(within,out))\n",
      "    def reducer(self, key, data):\n",
      "        out = ([None]*366)*4\n",
      "        within = [False]*4\n",
      "        for elem in data:\n",
      "            for i in range(4):\n",
      "                if elem[0][i]:\n",
      "                    within[i] = True\n",
      "            for i in range(len(elem[1])):\n",
      "                if(out[i] == None):\n",
      "                    out[i]=elem[1][i]\n",
      "        if within[1] and within[2]:\n",
      "            yield (key,(within,out))\n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_scripts/final_data_prep.py --stations ./stations.pkl.gz  $local_data  > mr_output/final_data_prep.small\n",
      "!head mr_output/final_data_prep.small"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_scripts/final_data_prep.py -r emr --emr-job-flow-id $job_flow_id --stations s3://Weather.GHNC/stations.pkl.gz hdfs:/weather/weather.csv > mr_output/final_data_prep\n",
      "!head mr_output/final_data_prep"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wc -l mr_output/geo_4meas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import string\n",
      "f = open(\"mr_output/final_data_prep\",\"r\")\n",
      "out = open('mr_output/final_data','w')\n",
      "for line in f:\n",
      "    F = line.translate(string.maketrans(\",\",\"\\t\"),'[]\" \\n').replace(\"null\",\"\")\n",
      "    out.write(F+\"\\n\")\n",
      "f.close()\n",
      "out.close()\n",
      "!gzip mr_output/final_data\n",
      "!zcaat mr_output/final_data.gz | head"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_scripts/feature_infill.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "\n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "import gzip\n",
      "import cPickle\n",
      "from sets import Set \n",
      "import os\n",
      "import numpy as np\n",
      "\n",
      "def readNum(x):\n",
      "    try:\n",
      "        out = float(x)\n",
      "    except Exception, e:\n",
      "        out = None\n",
      "    finally:\n",
      "        return out\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "    def configure_options(self):\n",
      "        super(MRWeather,self).configure_options()\n",
      "        self.add_file_option('--stations')\n",
      " \n",
      "\n",
      "    def mapper_init(self):\n",
      "        f = gzip.open( self.options.stations, \"rb\" )\n",
      "        pickleFile = cPickle.Unpickler( f )\n",
      "        self.stations = pickleFile.load()[['latitude','longitude','elevation']]\n",
      "        f.close()\n",
      "        self.keep = Set(['PRCP','TMIN','TMAX','SNWD'])\n",
      "        self.meas = {'PRCP':0,'TMIN':1,'TMAX':2,'SNWD':3}\n",
      "\n",
      "        \n",
      "    def mapper(self, _, line):\n",
      "        nan = float(\"NaN\")\n",
      "        try:\n",
      "            F=line.split('\\t')\n",
      "            if F[0]!='station':\n",
      "                station = F[0]\n",
      "                year    = int(F[1])\n",
      "                out     = np.zeros((4,366))\n",
      "                for i in range(4):\n",
      "                    if F[2+i] == \"false\":\n",
      "                        continue\n",
      "                    in_offset = 6+i*366\n",
      "                    for j in range(366):\n",
      "                        if F[in_offset+j] == \"\":\n",
      "                            out[i,j] = nan\n",
      "                        else:\n",
      "                            try:\n",
      "                                out[i,j] = float(F[in_offset+j])\n",
      "                            except Exception, e:\n",
      "                                out[i,j] = nan\n",
      "                        A = out[i,:]\n",
      "                        print(A.shape)\n",
      "                        bad_indexes = np.isnan(A)\n",
      "                        good_indexes = np.logical_not(bad_indexes)\n",
      "                        print bad_indexes\n",
      "                        print \"TEST\"\n",
      "                        good_data = A[good_indexes]\n",
      "                        print good_data\n",
      "                        interpolated = np.interp(bad_indexes.nonzero()[0], good_indexes.nonzero()[0], good_data)\n",
      "                        print interpolated\n",
      "                        A[bad_indexes] = interpolated\n",
      "                        out[i::]=A\n",
      "                cov_mat = np.cov(out)\n",
      "                print ((station,year),1)\n",
      "                yield((station,year),1)\n",
      "        except Exception, e:\n",
      "            yield ((\"error\",str(e)), 1)\n",
      "            \n",
      "    def combiner(self, key, data):\n",
      "        yield (key,data)\n",
      "    def reducer(self, key, data):\n",
      "        yield (key,data)\n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_scripts/feature_infill.py --stations ./stations.pkl.gz  ./mr_output/final_data.small  > mr_output/feature_infill.small\n",
      "!head mr_output/feature_infill.small"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head mr_output/feature_infill.small"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!gunzip mr_output/final_data.gz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -100 ./mr_output/final_data > ./mr_output/final_data.small"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(4):\n",
      "    print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_scripts/pca.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "This is our main processing job, it does subjobs:\n",
      "  1. Runs the group by station/year (ie makes [prcp, tmin, tmax, snwd] vectors for each station year)\n",
      "  2. Performs basic infill (linear interpolation if populated, 0's if not populated)\n",
      "  3. Performs PCA an induvidual station.\n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "import gzip\n",
      "import cPickle\n",
      "from sets import Set \n",
      "import os\n",
      "import numpy as np\n",
      "\n",
      "nan = float(\"NaN\")\n",
      "def readNum(x):\n",
      "    out = None\n",
      "    try:\n",
      "        out = float(x)\n",
      "    except Exception, e:\n",
      "        out = nan\n",
      "    finally:\n",
      "        return out\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "    def steps(self):\n",
      "        return [\n",
      "            self.mr(mapper_init=self.grouper_init,\n",
      "                    mapper=self.grouper_mapper,\n",
      "                    combiner=self.grouper_reducer,\n",
      "                    reducer=self.grouper_reducer),\n",
      "            self.mr(mapper=self.pca_mapper,\n",
      "                    combiner=self.pca_reducer,\n",
      "                    reducer=self.pca_reducer)\n",
      "        ]\n",
      " \n",
      "    def configure_options(self):\n",
      "        super(MRWeather,self).configure_options()\n",
      "        self.add_file_option('--stations')\n",
      " \n",
      "\n",
      "    def grouper_init(self):\n",
      "        f = gzip.open( self.options.stations, \"rb\" )\n",
      "        pickleFile = cPickle.Unpickler( f )\n",
      "        self.stations = pickleFile.load()[['latitude','longitude','elevation']]\n",
      "        f.close()\n",
      "        self.keep = Set(['PRCP','TMIN','TMAX','SNWD'])\n",
      "        self.meas = {'PRCP':0,'TMIN':1,'TMAX':2,'SNWD':3}\n",
      "        \n",
      "    def grouper_mapper(self, _, line):\n",
      "        try:\n",
      "            F=line.split(',')\n",
      "            if F[0]!='station':\n",
      "                station = F[0]\n",
      "                measure = F[1]\n",
      "                year    = int(F[2])\n",
      "                out = ([None]*365)*4\n",
      "                within = [False]*4\n",
      "                if measure in self.keep and year >= 1950:\n",
      "                    #offset = 366*self.meas[measure]\n",
      "                    within[self.meas[measure]] = True\n",
      "                    goodCount = 0\n",
      "                    offset = 0\n",
      "                    A = F[3:]\n",
      "                \n",
      "                    if(len(A)>365):\n",
      "                        A=A[0:365]\n",
      "                    elif(len(A)<365):\n",
      "                        A = A + ([None] * (365 - len(A)))\n",
      "                    if(len(A)!=365):\n",
      "                        raise Exception(\"CORRECTION ERROR\" + str(len(A)))\n",
      "                    A = [ readNum(x) for x in F[3:] ]\n",
      "                    A = np.array(A)\n",
      "                    bad_indexes = np.isnan(A)\n",
      "                    good_indexes = np.logical_not(bad_indexes)\n",
      "                    \n",
      "                    if sum(good_indexes) >= 100:\n",
      "                        if 0 < sum(bad_indexes):\n",
      "                            good_data = np.array(A[good_indexes])\n",
      "                            #raise Exception(\"Trying to interpolate\" + str(good))\n",
      "                            interpolated = np.interp(bad_indexes.nonzero()[0], good_indexes.nonzero()[0], good_data)                            \n",
      "                            A[bad_indexes] = interpolated\n",
      "                        offset = 365*self.meas[measure]\n",
      "                        out[offset:(offset+365)] = A.tolist()\n",
      "                        stationInfo = self.stations.ix[station]\n",
      "                        lat = stationInfo['latitude']\n",
      "                        lon = stationInfo['longitude']\n",
      "                        yield ((station,lat,lon,year),(within,out))\n",
      "                    else:\n",
      "                        raise Exception(\"Not enough good indexes\")\n",
      "                else:\n",
      "                    raise Exception(\"Bad measure or year\")\n",
      "                \n",
      "        except Exception, e:\n",
      "            yield ((\"error\",\"gm\", str(e)), 1)\n",
      "            \n",
      "    def grouper_reducer(self, key, data):\n",
      "        if key[0] == \"error\":\n",
      "            yield(key,sum(data))\n",
      "            return\n",
      "        try:\n",
      "            out = [0]*(4*365)\n",
      "            within = [False]*4\n",
      "            for elem in data:\n",
      "                for i in range(4):\n",
      "                    offset = 365*i\n",
      "                    if elem[0][i] and not within[i]:\n",
      "                        within[i] = True\n",
      "                        out[offset:(offset+365)] = elem[1][offset:(offset+365)]\n",
      "            yield (key,(within,out))\n",
      "        except Exception, e:\n",
      "            yield ((\"error\",\"gr\",str(e)), 1)\n",
      "        \n",
      "    def pca_mapper(self,key,data):\n",
      "        try:\n",
      "            if key[0] == \"error\":\n",
      "                yield(key,data)\n",
      "                return\n",
      "            (station,lat,lon,year) = key\n",
      "            (within,line) = data\n",
      "            if within[1] and (not within[2]):\n",
      "                data[(2*365):(3*365)]=data[(1*365):(2*365)]\n",
      "            if within[2] and (not within[1]):\n",
      "                data[(1*365):(2*365)]=data[(2*365):(3*365)]\n",
      "            if not(within[1] or within[2]):\n",
      "                yield ((\"error\",\"Missing data\",str(within)),1)\n",
      "                return\n",
      "            yield ((station,lat,lon),(year,within,line))\n",
      "        except Exception, e:\n",
      "            yield ((\"error\",\"pm\",str(e)), 1)\n",
      "\n",
      "    def pca_reducer(self,key, data):\n",
      "        try:\n",
      "            if key[0] == \"error\":\n",
      "                yield(key,sum(data))\n",
      "                return\n",
      "            max_year = (0,0)\n",
      "            max_rec  = None\n",
      "            for year,within,rec in data:\n",
      "                if max_year < (sum(within),year):\n",
      "                    max_year = (sum(within),year)\n",
      "                    max_rec  = (year,within,rec)\n",
      "            if max_rec != None:\n",
      "                yield (key,max_rec)\n",
      "        except Exception, e:\n",
      "            yield ((\"error\",\"pr\",str(e)), 1)\n",
      "        \n",
      "        \n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_scripts/pca.py --stations ./stations.pkl.gz  $local_data  > mr_output/pca.small\n",
      "!head mr_output/pca.small"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "job_flow_id = 'j-LTOJMJ14G840'\n",
      "!python mr_scripts/pca.py -r emr --emr-job-flow-id $job_flow_id --stations s3://Weather.GHNC/stations.pkl.gz hdfs:/weather/weather.csv  > mr_output/pca.tsv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head mr_output/pca.tsv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Yoav:** No Explanations! :("
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}