{
 "metadata": {
  "name": "",
  "signature": "sha256:b8e1dfd5a603e9c85523014c9fc03c957851ca8d1618f2e4d2eb59539498f486"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###The data-science style of coding###\n",
      "1. Your goal is to analyze the data, the code is just a means to an end.\n",
      "1. You are a Data Scientist, not just a programmer.\n",
      "1. Use short cycles: \n",
      "    1. Start a notebook, \n",
      "    1. write a bit of code, \n",
      "    1. run on data, \n",
      "    1. visualize results, \n",
      "    1. write conclusions. \n",
      "    1. Package code into functions/classes and write into .py files\n",
      "    1. Write numerical results into a PKL file with a dictionary that hold the variables of interest. \n",
      "        \n",
      "###Project Teams ###\n",
      "Each team should include at least 3 people, each of which has one of the following responsibilities:\n",
      "1. Programmer: responsible to write most of the code and for it being correct and efficient.\n",
      "1. Statistician: Analyze the output of the statistical analysis, verify that they are correct using synthetic data. Identify the parameters to use: how many eigen-vectors, which measurements, which areas of the world etc. Propose hypotheses and test them.\n",
      "1. Story-teller: in charge of telling the overall story of the analysis and how it relates to the world's weather.\n",
      "\n",
      "###Specific comments based on HW2 submissions###\n",
      "1. To avoid very skinny or very wide regions: first partition into fixed size squares(say 10 latitude and 10 longitude) and then partition each of the squares (if it has enough measurements) into smaller pieces.\n",
      "1. Be sure you are calculating percentage of variance explained correctly. For a single station the mean should already explain most of the variance. Look for the knee in the graph for each group. Separate out the stations for which a small number of eigen-vectors explains a lot. As a rule of thumb, the number of eigenvectors you use should be smaller than 10.\n",
      "1. When merging, it can be ok to give up some of the error.\n",
      "1. Plot and try to interpret the mean/eigenvectors.\n",
      "1. Cosider the coefficients of the eigenvectors as a function of time and location. Are the coefficients of neighboring stations correlated? Is there a long term trend?\n",
      "1. To evaluate the quality of your model you can split the data into train and test. Construct the model using the training data and the check how well it fits using the test data. You can partition years or (better) partition stations.\n",
      "\n",
      "### On debugging ###\n",
      "1. I will create for you, for both of the datasets and both on HDFS and on S3, a sequence of files with randomly permuted random subsets of each file with sizes $1/2,1/4,1/8,...,1/1024$ of the original file size.\n",
      "1. Do the merging on a single large EC2 instance, not using hadoop.\n",
      "1. Before using EMR perform local test with sets of increasing size (go up to 100MB input file)\n",
      "1. When you use hadoop and it crashes or takes a very long time (more than 30 minutes) do the following:\n",
      "    1. scale down to the largest size you tried on local.\n",
      "    1. Use ECatch (remember to disable after error found and running in production)\n",
      "    1. Add log prints `sys.stderr.write('status message')`\n",
      "    1. Study the generated stderr files."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Useful code snippets"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Memory Leaks"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If a map or reduce job crashes on large input the reason might be a memory leak. In a memory leak objects are allocated but not released, causing the taks to consume more and more memory over time. To check whether this is happening, add a call to \"resources\":"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile testMemUsage.py\n",
      "import resource,sys\n",
      "from numpy import random\n",
      "logfile=sys.stderr\n",
      "\n",
      "for i in range(9):\n",
      "    v=random.rand(10**i)\n",
      "    logfile.write('size of vector=%10d, memory size: %s bytes\\n'\\\n",
      "          %(len(v),resource.getrusage(resource.RUSAGE_SELF).ru_maxrss))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting testMemUsage.py\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python testMemUsage.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "size of vector=         1, memory size: 13762560 bytes\r\n",
        "size of vector=        10, memory size: 13762560 bytes\r\n",
        "size of vector=       100, memory size: 13762560 bytes\r\n",
        "size of vector=      1000, memory size: 13762560 bytes\r\n",
        "size of vector=     10000, memory size: 13848576 bytes\r\n",
        "size of vector=    100000, memory size: 14651392 bytes\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "size of vector=   1000000, memory size: 22654976 bytes\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "size of vector=  10000000, memory size: 102670336 bytes\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "size of vector= 100000000, memory size: 902684672 bytes\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can see that the stand-alon python process requires about 14 MB of memory. When the vector size gets to 100,000 it consumes about 1MB (8 bytes per entry) and therefor there is a measureable effect on the total memory usage."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Timing and the benefits of Numpy Arrays###\n",
      "To check how long a single run of the mapper take, use the \"time\" package.\n",
      "\n",
      "Whenever possible, use Numpy, rather than python lists. It will make your program >100 times faster!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "a=random.rand(1000000)\n",
      "b=random.rand(1000000)\n",
      "t1=time.clock()\n",
      "for method in ['numpy','comprehension','for loop']:\n",
      "    t1=time.clock()    \n",
      "    if method=='numpy':\n",
      "        print dot(a,b),\n",
      "    elif method=='comprehension':\n",
      "        print sum([a[i]*b[i] for i in range(len(a))]),\n",
      "    elif method=='for loop':\n",
      "        Sum=0\n",
      "        for i in range(len(a)):\n",
      "            Sum+=a[i]*b[i]\n",
      "        print Sum,\n",
      "    t2=time.clock()    \n",
      "    print method,t2-t1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "249728.864553 numpy 0.001891\n",
        "249728.864553"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " comprehension 0.996164\n",
        "249728.864553"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " for loop 0.9859\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}