{
 "metadata": {
  "name": "",
  "signature": "sha256:2c67e8f97ea60eafeb39d4a967585a93f58f33a2fd7554c64f3e595ad14fe975"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<span style=\"color:blue\" > PCA starts here, using Professor's pre-built partitioned tree and stations. </span>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sklearn as sk\n",
      "import sys\n",
      "import pickle\n",
      "home_dir='/home/ubuntu/UCSD_BigData'\n",
      "dat_dir='/home/ubuntu/UCSD_BigData/data/weather'\n",
      "sys.path.append(home_dir+'/utils')\n",
      "from find_waiting_flow import *\n",
      "from AWS_keypair_management import *\n",
      "localData=home_dir+'/data/weather/ALL.head.csv'\n",
      "station=dat_dir+'/ghcnd-stations.txt'\n",
      "readme = dat_dir+'/ghcnd-readme.txt'\n",
      "import re\n",
      "import os\n",
      "import random\n",
      "## AWS credentials\n",
      "Creds= pickle.load(open('/home/ubuntu/Vault/Creds.pkl','rb'))\n",
      "pair=Creds['mrjob']\n",
      "key_id=pair['key_id']\n",
      "secret_key=pair['secret_key']\n",
      "ID=pair['ID']\n",
      "job_flow_id=find_waiting_flow(key_id,secret_key)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## copy Weather.GHNC from professor's bucket\n",
      "from boto.s3.connection import S3Connection,OrdinaryCallingFormat\n",
      "from boto.s3.key import Key\n",
      "conn = S3Connection(key_id, secret_key,calling_format = OrdinaryCallingFormat())\n",
      "weather = conn.get_bucket(\"Weather.GHNC\")\n",
      "# # download a S3 file to local disk\n",
      "# key = weather.get_key('compiled_statistics.pkl.gz')\n",
      "# key.get_contents_to_filename('/home/ubuntu/UCSD_BigData/data/weather/compiled_statistics.pkl.gz')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tree = pickle.load(open('/home/ubuntu/UCSD_BigData/data/weather/tree.pkl'))\n",
      "ptree = tree['Partition_Tree']\n",
      "pstn = tree['Partitioned_Stations']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile concatTminTmax.py\n",
      "#!/usr/bin/python\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "from sys import stderr\n",
      "import pandas as pd\n",
      "import re,pickle,base64,zlib\n",
      "\n",
      "def decode(eVal):\n",
      "    \"\"\" Decode a string into a value \"\"\"\n",
      "    return pickle.loads(zlib.decompress(base64.b64decode(eVal)))\n",
      "\n",
      "def encode(Value):\n",
      "    \"\"\" Encode a value as a string \"\"\"\n",
      "    return base64.b64encode(zlib.compress(pickle.dumps(Value),9))\n",
      " \n",
      "\n",
      "class concatTminTmax(MRJob):\n",
      "    '''This class yields all the qualified records of TMAX and TMIN'''\n",
      "    def concat_mapper(self, _, line):\n",
      "        try:\n",
      "            rec = line.split(\",\")\n",
      "            stn,meas,year = rec[:3]\n",
      "            if meas=='TMAX' or meas=='TMIN': # if this is tmax or tmin\n",
      "                if len(filter(None,rec[3:]))/365.0>0.5: # measurements during >50% days of the year \n",
      "                    yield stn+\":\"+year,encode([meas,rec[3:]])\n",
      "        except Exception, e:\n",
      "            stderr.write('Error in line:\\n'+str(line[:5]))\n",
      "            stderr.write(str(e))\n",
      "            ### You need a \"Yield\" here, otherwise, in case of an exception, \n",
      "            ### the whole process will crash.\n",
      "\n",
      "    def concat_reducer(self, key, value):\n",
      "        try:\n",
      "            stn,year=key.split(\":\")\n",
      "            recs = list(value)\n",
      "            trec={} # at this time, use a dictionary to store TMAX and TMIN data. order doesn't matter\n",
      "            if len(recs)==2: # if this station:year has both TMAX and TMIN\n",
      "                stderr.write(stn+\"\\t\"+year+\"\\n\")\n",
      "                for r in recs:\n",
      "                    meas,vec = decode(r)\n",
      "                    trec[meas]=vec\n",
      "                #k1,k2=trec.keys() # for test \n",
      "                #stderr.write(stn+\"\\t\"+year+\"\\t\"+k1+\"\\t\"+str(trec[k1][:10])+\"\\t\"+k2+\"\\t\"+str(trec[k2][:10])+\"\\n\")\n",
      "                yield stn,encode(trec)\n",
      "\n",
      "        except Exception as e:\n",
      "            stderr.write('Error:')\n",
      "            stderr.write(str(e)+\"\\t\")\n",
      "    \n",
      "\n",
      "    def steps(self):\n",
      "        return [\n",
      "            self.mr(mapper=self.concat_mapper,\n",
      "                    reducer=self.concat_reducer)\n",
      "        ]\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    concatTminTmax.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting concatTminTmax.py\n"
       ]
      }
     ],
     "prompt_number": 261
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!python concatTminTmax.py -r emr --emr-job-flow-id  $job_flow_id hdfs:/weather/weather.csv --output-dir s3://weiwei.bucket/data/all_dat.csv/  --no-output\n",
      "#!python meas_count.py -r emr --emr-job-flow-id  $job_flow_id hdfs:/weather/weather.csv  > meas_weight_all # "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /tmp/concatTminTmax.ubuntu.20140526.053832.184200\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://weiwei.bucket/scratch/concatTminTmax.ubuntu.20140526.053832.184200/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding our job to existing job flow j-LTOJMJ14G840\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 31.0s ago, status RUNNING: Running step (concatTminTmax.ubuntu.20140526.053832.184200: Step 1 of 1)\r\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile samplePCADat.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "create a sample set for PCA test\n",
      "\"\"\"\n",
      "\n",
      "import random\n",
      "\n",
      "# def decode(eVal):\n",
      "#     \"\"\" Decode a string into a value \"\"\"\n",
      "#     return pickle.loads(zlib.decompress(base64.b64decode(eVal)))\n",
      "\n",
      "# def encode(Value):\n",
      "#     \"\"\" Encode a value as a string \"\"\"\n",
      "#     return base64.b64encode(zlib.compress(pickle.dumps(Value),9))\n",
      "\n",
      "class samplePCADat(MRJob):\n",
      "    def sample_dat_mapper(self,_,line):\n",
      "        try:\n",
      "            stn,trecEncode = line.split(\"\\t\")\n",
      "#             stderr.write(\"Line: \"+\"\\t\"+stn+\"\\t\"+trecEncode[:10]+\"\\n\")\n",
      "            if random.random()<0.01:\n",
      "                yield stn.strip('\\\"'),trecEncode.strip('\\\"')\n",
      "        except Exception, e:\n",
      "            stderr.write('Error in line:\\n'+str(line[:5]))\n",
      "            stderr.write(str(e))\n",
      "\n",
      "    def steps(self):\n",
      "        return [\n",
      "            self.mr(mapper=self.sample_dat_mapper)\n",
      "        ]\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    samplePCADat.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting samplePCADat.py\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python samplePCADat.py -r emr --emr-job-flow-id  $job_flow_id s3://weiwei.bucket/data/all_dat.csv/ > sample_dat_10k.csv \n",
      "#--output-dir s3://weiwei.bucket/data/sample_dat.csv/  --no-output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /tmp/samplePCADat.ubuntu.20140526.192324.390970\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://weiwei.bucket/scratch/samplePCADat.ubuntu.20140526.192324.390970/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding our job to existing job flow j-LTOJMJ14G840\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 31.0s ago, status RUNNING: Running step (samplePCADat.ubuntu.20140526.192324.390970: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 62.1s ago, status RUNNING: Running step (samplePCADat.ubuntu.20140526.192324.390970: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job completed.\r\n",
        "Running time was 55.0s (not counting time spent waiting for the EC2 instances)\r\n",
        "ec2_key_pair_file not specified, going to S3\r\n",
        "Fetching counters from S3...\r\n",
        "Waiting 5.0s for S3 eventual consistency\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters may not have been uploaded to S3 yet. Try again in 5 minutes with: mrjob fetch-logs --counters j-LTOJMJ14G840\r\n",
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "Streaming final output from s3://weiwei.bucket/scratch/samplePCADat.ubuntu.20140526.192324.390970/output/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "removing tmp directory /tmp/samplePCADat.ubuntu.20140526.192324.390970\r\n",
        "Removing all files in s3://weiwei.bucket/scratch/samplePCADat.ubuntu.20140526.192324.390970/\r\n"
       ]
      }
     ],
     "prompt_number": 373
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile stnDistSample.py\n",
      "#!/usr/bin/python\n",
      "\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "from sys import stderr\n",
      "import re,pickle,base64,zlib\n",
      "\n",
      "def decode(eVal):\n",
      "    \"\"\" Decode a string into a value \"\"\"\n",
      "    return pickle.loads(zlib.decompress(base64.b64decode(eVal)))\n",
      "\n",
      "def encode(Value):\n",
      "    \"\"\" Encode a value as a string \"\"\"\n",
      "    return base64.b64encode(zlib.compress(pickle.dumps(Value),9))\n",
      "\n",
      "class stnDistSample(MRJob):\n",
      "    \"\"\"\n",
      "    This class calculates the weight distribution of stations in sample_dat.csv/sample_dat_10k.csv\n",
      "    \"\"\"\n",
      "    def pca_prescreen_mapper(self,_,line):\n",
      "        try:\n",
      "            stn,trecEn = line.split(\"\\t\")\n",
      "            stn=stn.strip('\\\"')\n",
      "            yield stn,1\n",
      "        except Exception, e:\n",
      "            stderr.write('Error in line:\\n'+str(line[:5]))\n",
      "            stderr.write(str(e))\n",
      "    def pca_prescreen_reducer(self,key,value):\n",
      "        try:\n",
      "            outkey=key\n",
      "            outval=sum(list(value))\n",
      "            if outval>5: # change this value to output stations of at least this number of records. In this sample, \"ITE00100550\" and \\\n",
      "                         # \"USC00120177\" have more than 5 records\n",
      "                yield outkey,outval\n",
      "        except Exception as e:\n",
      "            stderr.write('Error:')\n",
      "            stderr.write(str(e)+\"\\t\")\n",
      "            \n",
      "    def steps(self):\n",
      "        return [\n",
      "            self.mr(mapper=self.pca_prescreen_mapper,\n",
      "                    reducer=self.pca_prescreen_reducer)\n",
      "        ]\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    stnDistSample.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting stnDistSample.py\n"
       ]
      }
     ],
     "prompt_number": 383
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!python stnDistSample.py -r local sample_dat_10k.csv > stnWtDistSample.csv\n",
      "#!python stnDistSample.py -r emr --emr-job-flow-id  $job_flow_id s3://weiwei.bucket/data/sample_dat.csv/ > stnWtDistSample.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 385
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This following section is PCA on a single station. The latter section PCA on all stations was developed on this. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile samplePCA.py\n",
      "#!/usr/bin/python\n",
      "\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "from sys import stderr\n",
      "import pandas as pd\n",
      "import re,pickle,base64,zlib\n",
      "import numpy as np\n",
      "\n",
      "def decode(eVal):\n",
      "    \"\"\" Decode a string into a value \"\"\"\n",
      "    return pickle.loads(zlib.decompress(base64.b64decode(eVal)))\n",
      "\n",
      "def encode(Value):\n",
      "    \"\"\" Encode a value as a string \"\"\"\n",
      "    return base64.b64encode(zlib.compress(pickle.dumps(Value),9))\n",
      "\n",
      "def checkThreshold(x):\n",
      "    '''The variance explanation threshold to 99%,return the index of the element once reach 99%'''\n",
      "    x=list(x)\n",
      "#     stderr.write(str(x[:10]))\n",
      "    for i in x:\n",
      "        if i > 0.99:\n",
      "            return x.index(i)\n",
      "\n",
      "class mrpca(MRJob):\n",
      "    \"\"\"\n",
      "    run PCA on data from one station\n",
      "    \"\"\"\n",
      "    def NN(self,vec):\n",
      "        \"\"\"nearest neighbor method to substitute missing values in record the nearest left neighbor\"\"\"\n",
      "        # if there is None\n",
      "        if not None in vec: # None is the only representation of missing value\n",
      "            return vec\n",
      "        else:\n",
      "            for i in xrange(len(vec)):\n",
      "                if vec[i]==None:\n",
      "                    if i>0: # if vec[i] is not the first item, make it equal to its left neighbor\n",
      "                        vec[i]=vec[i-1]\n",
      "                    else:  # if vec[i] is the first item, make it equal to the first valid value in this list\n",
      "                        vec[i]=filter(None,vec)[0]\n",
      "            return vec\n",
      "            \n",
      "    def str2flt(self,vec):\n",
      "        \"\"\"convert string elements to float; missing values are replaced with None\"\"\"\n",
      "        newvec=[]\n",
      "        for v in vec:\n",
      "            try:\n",
      "                newv=float(v)\n",
      "            except:\n",
      "                newv=None\n",
      "            finally:\n",
      "                newvec.append(newv)\n",
      "        return newvec\n",
      "                \n",
      "    def pca_dat_prep(self, _, line):\n",
      "        '''collect records of one station, preprocessing data, create 365*2 array for station/year'''\n",
      "        try:\n",
      "            stn,trecEn = line.split(\"\\t\")\n",
      "            stn=stn.strip('\\\"')\n",
      "            if stn==\"USC00120177\": # experiment with \"USC00120177\"   7 records\n",
      "                trec=decode(trecEn.strip('\\\"'))\n",
      "                # array element type str->float, drop NaN and substitude the value with nearest neighbor\n",
      "                tmax = self.NN(self.str2flt(trec[\"TMAX\"]))\n",
      "                tmin = self.NN(self.str2flt(trec[\"TMIN\"]))\n",
      "                # double check\n",
      "                if None in tmax or None in tmin:\n",
      "                    stderr.write(\"None exists\\n\")\n",
      "#                 stderr.write(\"tmax: \"+\"\\t\"+str(tmax)+\"\\n\") # \n",
      "                datArr = np.array([tmax,tmin]).T  # 365*2\n",
      "#                 stderr.write(\"dataArr \"+str(datArr.shape)+\"\\n\")\n",
      "                yield stn, encode(datArr)\n",
      "        except Exception, e:\n",
      "            stderr.write('Error in line:\\n'+str(line[:5]))\n",
      "            stderr.write(str(e))\n",
      "\n",
      "    def pca_indi_sum(self,key,value):\n",
      "        '''get the sum of measurement 2-D numpy arrays'''\n",
      "        try:\n",
      "            stn=key\n",
      "            vals=list(value)\n",
      "            arrays = [decode(x) for x in vals]\n",
      "            measSum=np.zeros(shape=arrays[0].shape) # neasSum type: numpy array\n",
      "#             stderr.write(\"measSum initialized\\n\")\n",
      "            for arr in arrays:\n",
      "                measSum+=arr # sum over arrays\n",
      "            yield stn,(encode(measSum),encode(len(arrays)),encode(arrays)) # sum of arrays\n",
      "        except Exception as e:\n",
      "            stderr.write('Error:')\n",
      "            stderr.write(str(e)+\"\\t\")\n",
      "            \n",
      "    def pca_indi_mean(self,key,value):\n",
      "        '''calculate the mean vector of this node/station'''\n",
      "        try:\n",
      "            stn=key\n",
      "            vals=[v for v in value]\n",
      "            measSumEn,countEn,arraysEn = vals[0]\n",
      "            measSum = decode(measSumEn)\n",
      "            count=decode(countEn)\n",
      "            mean = measSum/float(count)\n",
      "#             stderr.write(stn+\"\\t\"+str(mean))\n",
      "            yield stn,(encode(mean),arraysEn)\n",
      "        except Exception as e:\n",
      "            stderr.write('Error:')\n",
      "            stderr.write(str(e)+\"\\t\")    \n",
      "\n",
      "    \n",
      "    def pca_indi_cov(self,key,value):\n",
      "        \"calculate variance and covariance matrix\"\n",
      "        try:\n",
      "            stn=key\n",
      "            vals=list(value)\n",
      "            meanEn,arraysEn = vals[0]\n",
      "            mean=decode(meanEn)\n",
      "            arrays=decode(arraysEn) # shape of each array (365,2)\n",
      "            cov=[]\n",
      "            for arr in arrays:\n",
      "                v=arr-mean# variance array\n",
      "                cov.append(np.dot(v,v.T)) ## Here should use np.dot rather than np.outer. The numpy definition is confusing. \n",
      "                                          ## if np.outer, the dimension is incorrect (730*730). It shuld be 365*365\n",
      "#             stderr.write(\"shape of cov[0]: \"+\"\\t\"+str(cov[0].shape))\n",
      "            yield stn,encode(cov)\n",
      "        except Exception as e:\n",
      "            stderr.write('Error:')\n",
      "            stderr.write(str(e)+\"\\n\")\n",
      "            \n",
      "    def pca_indi_svd(self,key,value):\n",
      "        \"\"\"get eigen vectors explaining 99% of variance\"\"\"\n",
      "        try:\n",
      "            stn=key\n",
      "            vals=list(value)\n",
      "            covArrEn = vals[0] # encoded covariance arrays\n",
      "#             stderr.write(\"cov: \"+\"\\t\"+str(len(decode(covArrEn)))+\"\\n\"+str(decode(covArrEn)[:5])+\"\\n\")\n",
      "            covArr = decode(covArrEn)\n",
      "            covSum = np.zeros(covArr[0].shape)\n",
      "            for cov in covArr:\n",
      "                covSum+=cov\n",
      "            meanCov = covSum/float(len(covArr))\n",
      "            ## SVD below\n",
      "            U,D,V=np.linalg.svd(cov)\n",
      "            varXpln = np.cumsum(D[:])/np.sum(D) # cummulative density of explained variance\n",
      "#             stderr.write(\"var explained: \\n\"+str(varXpln))\n",
      "#             stderr.write(\"shape of U: \"+\"\\t\"+str(U.shape))\n",
      "#             stderr.write(\"shape of D: \"+\"\\t\"+str(D.shape))\n",
      "#             stderr.write(\"shape of V: \"+\"\\t\"+str(V.shape))\n",
      "            ## eigen vector selection, need explain 99% variance\n",
      "            cut=checkThreshold(varXpln)\n",
      "#             stderr.write(\"cut: \"+'\\n'+str(cut))\n",
      "            ev = U[:,:cut] ## selected eigen vectors\n",
      "#             stderr.write(\"Results: \\n\"+str(ev.shape)+\"\\n\"+str(ev)+'\\n')\n",
      "            yield stn,encode(ev)\n",
      "        except Exception as e:\n",
      "            stderr.write('Error:')\n",
      "            stderr.write(str(e)+\"\\n\")\n",
      "            \n",
      "    def steps(self):\n",
      "        return [\n",
      "            self.mr(mapper=self.pca_dat_prep,\n",
      "                    reducer=self.pca_indi_sum),\n",
      "            self.mr(reducer=self.pca_indi_mean),\n",
      "            self.mr(reducer=self.pca_indi_cov),\n",
      "            self.mr(reducer=self.pca_indi_svd)\n",
      "            \n",
      "        ]\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    mrpca.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting samplePCA.py\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python samplePCA.py -r emr --emr-job-flow-id  $job_flow_id sample_dat_10k.csv > samplePCA.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /tmp/samplePCA.ubuntu.20140527.010045.554912\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://weiwei.bucket/scratch/samplePCA.ubuntu.20140527.010045.554912/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding our job to existing job flow j-31UKS93V80CN7\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 30.8s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>81cf5826-e53a-11e3-977d-81d1fc5a197d</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>8dc071b0-e53a-11e3-8c68-dfb11431f3fe</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 30.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 111.5s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 142.3s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 173.2s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 203.9s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 234.7s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 265.5s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 296.3s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 327.1s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 358.0s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 388.7s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>572dfe6e-e53b-11e3-9423-c97367f9860b</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 439.5s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 470.3s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 501.0s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>9a231b92-e53b-11e3-b43a-872b56d6dfca</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>a614a9de-e53b-11e3-9423-c97367f9860b</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 30.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 581.9s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 612.7s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 643.5s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 674.3s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 705.2s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 736.0s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 766.7s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 797.5s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 828.3s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 859.1s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 889.8s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 920.6s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 951.4s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 982.3s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1013.1s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1043.9s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1074.7s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>f00ba41f-e53c-11e3-955c-1fb30f4201c5</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1125.5s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1156.4s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1187.2s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1218.0s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1248.7s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1279.5s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1316.6s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1347.4s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1378.3s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1409.1s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1440.0s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1470.9s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1501.7s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1532.6s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>0101e06b-e53e-11e3-9423-c97367f9860b</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1583.4s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1614.2s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1644.9s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1675.7s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1706.5s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1737.4s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1768.2s ago, status RUNNING: Running step\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job on job flow j-31UKS93V80CN7 failed with status WAITING: Waiting after step failed\r\n",
        "Logs are in s3://yoav.hadoop/log/j-31UKS93V80CN7/\r\n",
        "ec2_key_pair_file not specified, going to S3\r\n",
        "Scanning S3 logs for probable cause of failure\r\n",
        "Waiting 5.0s for S3 eventual consistency\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>90e0eeb9-e53e-11e3-a7f3-054eed488613</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Attempting to terminate job...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traceback (most recent call last):\r\n",
        "  File \"samplePCA.py\", line 167, in <module>\r\n",
        "    mrpca.run()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/job.py\", line 494, in run\r\n",
        "    mr_job.execute()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/job.py\", line 512, in execute\r\n",
        "    super(MRJob, self).execute()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/launch.py\", line 147, in execute\r\n",
        "    self.run_job()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/launch.py\", line 213, in run_job\r\n",
        "    self.stdout.flush()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/runner.py\", line 614, in __exit__\r\n",
        "    self.cleanup()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/emr.py\", line 1010, in cleanup\r\n",
        "    super(EMRJobRunner, self).cleanup(mode=mode)\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/runner.py\", line 560, in cleanup\r\n",
        "    self._cleanup_job()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/emr.py\", line 1084, in _cleanup_job\r\n",
        "    self._opts['ec2_key_pair_file'])\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/ssh.py\", line 200, in ssh_terminate_single_job\r\n",
        "    ssh_bin, address, ec2_key_pair_file, ['hadoop', 'job', '-list']))\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/ssh.py\", line 82, in ssh_run\r\n",
        "    p = Popen(args, stdout=PIPE, stderr=PIPE, stdin=PIPE)\r\n",
        "  File \"/home/ubuntu/anaconda/lib/python2.7/subprocess.py\", line 709, in __init__\r\n",
        "    errread, errwrite)\r\n",
        "  File \"/home/ubuntu/anaconda/lib/python2.7/subprocess.py\", line 1326, in _execute_child\r\n",
        "    raise child_exception\r\n",
        "TypeError: execv() arg 2 must contain only strings\r\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "I don't see any problem with outer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Outer works as expected and dot gives the dot product regardless of the \n",
      "#orientation of the vector (row or column)\n",
      "x=np.random.rand(10)\n",
      "y=np.random.rand(10)\n",
      "print shape(outer(x,y))\n",
      "print dot(x,y),dot(x,y.T),dot(x.T,y),"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(10, 10)\n",
        "1.62380613894 1.62380613894 1.62380613894\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile weatherPCA.py\n",
      "#!/usr/bin/python\n",
      "\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "from sys import stderr\n",
      "import pandas as pd\n",
      "import re,pickle,base64,zlib\n",
      "import numpy as np\n",
      "\n",
      "def decode(eVal):\n",
      "    \"\"\" Decode a string into a value \"\"\"\n",
      "    return pickle.loads(zlib.decompress(base64.b64decode(eVal)))\n",
      "\n",
      "def encode(Value):\n",
      "    \"\"\" Encode a value as a string \"\"\"\n",
      "    return base64.b64encode(zlib.compress(pickle.dumps(Value),9))\n",
      "\n",
      "def checkThreshold(x):\n",
      "    x=list(x)\n",
      "    for i in x:\n",
      "        if i > 0.99:\n",
      "            return x.index(i)\n",
      "\n",
      "class weatherPCA(MRJob):\n",
      "    \"\"\"\n",
      "    run PCA on data from all stations\n",
      "    \"\"\"\n",
      "    def NN(self,vec):\n",
      "        \"\"\"nearest neighbor method to substitute missing values in record the nearest left neighbor\"\"\"\n",
      "        # if there is None\n",
      "        if not None in vec: # None is the only representation of missing value\n",
      "            return vec\n",
      "        else:\n",
      "            for i in xrange(len(vec)):\n",
      "                if vec[i]==None:\n",
      "                    if i>0: # if vec[i] is not the first item, make it equal to its left neighbor\n",
      "                        vec[i]=vec[i-1]\n",
      "                    else:  # if vec[i] is the first item, make it equal to the first valid value in this list\n",
      "                        vec[i]=filter(None,vec)[0]\n",
      "            return vec\n",
      "            \n",
      "    def str2flt(self,vec):\n",
      "        \"\"\"convert string elements to float; missing values are replaced with None\"\"\"\n",
      "        newvec=[]\n",
      "        for v in vec:\n",
      "            try:\n",
      "                newv=float(v)\n",
      "            except:\n",
      "                newv=None\n",
      "            finally:\n",
      "                newvec.append(newv)\n",
      "        return newvec\n",
      "                \n",
      "    def pca_dat_prep(self, _, line):\n",
      "        '''\n",
      "        Input is a station and the records of tmax and tmin of some year.\\\n",
      "        Output is station and encoded 365*2 numpy arrays\n",
      "        '''\n",
      "        try:\n",
      "            stn,trecEn = line.split(\"\\t\")\n",
      "            stn=stn.strip('\\\"')\n",
      "            trec=decode(trecEn.strip('\\\"'))\n",
      "            # array element type str->float, drop NaN and substitude the value with nearest neighbor\n",
      "            tmax = self.NN(self.str2flt(trec[\"TMAX\"]))\n",
      "            tmin = self.NN(self.str2flt(trec[\"TMIN\"]))\n",
      "            # for double check\n",
      "            if None in tmax or None in tmin:\n",
      "                stderr.write(\"None exists\\n\")\n",
      "#           stderr.write(\"tmax: \"+\"\\t\"+str(tmax)+\"\\n\") # \n",
      "            datArr = np.array([tmax,tmin]).T\n",
      "#           stderr.write(\"dataArr \"+str(datArr.shape)+\"\\n\")\n",
      "            yield stn, encode(datArr)\n",
      "        except Exception, e:\n",
      "            stderr.write('Error in line:\\n'+str(line[:5]))\n",
      "            stderr.write(str(e))\n",
      "\n",
      "    def pca_indi_sum(self,key,value):\n",
      "        '''get the sum of measurement 2-D numpy arrays'''\n",
      "        try:\n",
      "            stn=key\n",
      "            vals=list(value)\n",
      "            arrays = [decode(x) for x in vals]#x = x[~numpy.isnan(x)] # remove nan\n",
      "            measSum=np.zeros(shape=arrays[0].shape) # neasSum type: numpy array\n",
      "#             stderr.write(\"measSum initialized\\n\")\n",
      "            for arr in arrays:\n",
      "                measSum+=arr\n",
      "            yield stn,(encode(measSum),encode(len(arrays)),encode(arrays)) # sum of arrays\n",
      "        except Exception as e:\n",
      "            stderr.write('Error:')\n",
      "            stderr.write(str(e)+\"\\t\")\n",
      "            \n",
      "    def pca_indi_mean(self,key,value):\n",
      "        '''calculate the mean vector of this node/station'''\n",
      "        try:\n",
      "            stn=key\n",
      "            vals=[v for v in value]\n",
      "            measSumEn,countEn,arraysEn = vals[0]\n",
      "            measSum = decode(measSumEn)\n",
      "            count=decode(countEn)\n",
      "            mean = measSum/float(count)\n",
      "#             stderr.write(stn+\"\\t\"+str(mean))\n",
      "            yield stn,(encode(mean),arraysEn)\n",
      "        except Exception as e:\n",
      "            stderr.write('Error:')\n",
      "            stderr.write(str(e)+\"\\t\")    \n",
      "\n",
      "    \n",
      "    def pca_indi_cov(self,key,value):\n",
      "        \"calculate variance and covariance matrix\"\n",
      "        try:\n",
      "            stn=key\n",
      "            vals=list(value)\n",
      "            meanEn,arraysEn = vals[0]\n",
      "            mean=decode(meanEn)\n",
      "            arrays=decode(arraysEn) # shape of each array (365,2)\n",
      "            cov=[]\n",
      "            for arr in arrays: # remove [:2], this is just for testing\n",
      "                v=arr-mean# variance array\n",
      "                cov.append(np.dot(v,v.T)) ## Here should use np.dot rather than np.outer. The np definition is confusing. \n",
      "                                          ## if np.outer, the dimension is incorrect. shuld be 365*365\n",
      "            yield stn,encode(cov)\n",
      "        except Exception as e:\n",
      "            stderr.write('Error:')\n",
      "            stderr.write(str(e)+\"\\n\")\n",
      "            \n",
      "    def pca_indi_svd(self,key,value):\n",
      "        \"\"\"get eigen vectors explaining 99% of variance\"\"\"\n",
      "        try:\n",
      "            stn=key\n",
      "            vals=list(value)\n",
      "            covArrEn = vals[0] # encoded covariance arrays\n",
      "#             stderr.write(\"cov: \"+\"\\t\"+str(len(decode(covArrEn)))+\"\\n\"+str(decode(covArrEn)[:5])+\"\\n\")\n",
      "            covArr = decode(covArrEn)\n",
      "            covSum = np.zeros(covArr[0].shape)\n",
      "            for cov in covArr:\n",
      "                covSum+=cov\n",
      "            meanCov = covSum/float(len(covArr))\n",
      "            ## SVD below\n",
      "            U,D,V=np.linalg.svd(cov)\n",
      "            varXpln = np.cumsum(D[:])/np.sum(D) # cummulative density of explained variance\n",
      "#             stderr.write(\"var explained: \\n\"+str(varXpln))\n",
      "            ## eigen vector selection, need explain 99% variance\n",
      "            cut=checkThreshold(varXpln)\n",
      "#             stderr.write(\"cut: \"+'\\n'+str(cut))\n",
      "            ev = U[:,:cut] ## selected eigen vectors\n",
      "#             stderr.write(\"Results: \\n\"+str(ev.shape)+\"\\n\"+str(ev)+'\\n')\n",
      "            yield stn,encode(ev)\n",
      "        except Exception as e:\n",
      "            stderr.write('Error:')\n",
      "            stderr.write(str(e)+\"\\n\")\n",
      "            \n",
      "    def steps(self):\n",
      "        return [\n",
      "            self.mr(mapper=self.pca_dat_prep,\n",
      "                    reducer=self.pca_indi_sum),\n",
      "            self.mr(reducer=self.pca_indi_mean),\n",
      "            self.mr(reducer=self.pca_indi_cov),\n",
      "            self.mr(reducer=self.pca_indi_svd)\n",
      "            \n",
      "        ]\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    weatherPCA.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing weatherPCA.py\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python weatherPCA.py -r emr --emr-job-flow-id  $job_flow_id sample_dat_10k.csv > samplePCA_allnodes.csv\n",
      "## completed\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /tmp/weatherPCA.ubuntu.20140527.013707.958277\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://weiwei.bucket/scratch/weatherPCA.ubuntu.20140527.013707.958277/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding our job to existing job flow j-31UKS93V80CN7\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 30.9s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 1 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 61.7s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 1 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 92.6s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 1 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 123.4s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 2 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>ce402f65-e53f-11e3-80e8-ff6cff06198c</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 174.3s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 2 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>ec93dbb4-e53f-11e3-bea8-dbf80bac8b69</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 225.1s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 255.9s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 286.7s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 317.5s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 348.3s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 379.1s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 410.4s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 441.2s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 472.0s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 502.8s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 533.6s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 564.5s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 595.3s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 626.2s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 657.0s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 687.9s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>1ebcc71a-e541-11e3-8362-0f887c06ae20</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>2aadb993-e541-11e3-af71-7d8b78bb4770</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 30.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 768.9s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 799.7s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 830.5s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>73bda54c-e541-11e3-acfe-a31808eb12d5</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>7fb15671-e541-11e3-a7f3-054eed488613</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 30.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 911.5s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 942.4s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 973.3s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>c8dae368-e541-11e3-a7f3-054eed488613</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1024.2s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>e73371d6-e541-11e3-81ac-09de5656b974</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>f324d8b1-e541-11e3-acfe-a31808eb12d5</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 30.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1105.2s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1136.0s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1166.9s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1197.7s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1228.6s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1259.4s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>735c555a-e542-11e3-977d-81d1fc5a197d</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>7f4d473d-e542-11e3-a13b-cf267f9d23d6</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 30.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>913579e2-e542-11e3-9fde-05f53a330f8a</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 45.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1385.4s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1416.2s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1447.0s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1477.9s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>f594838e-e542-11e3-aa87-172672d76e00</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1528.8s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 3 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>13eceac4-e543-11e3-9077-5114ea9dc6a3</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>1fe111b8-e543-11e3-9077-5114ea9dc6a3</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 30.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>31c9e03c-e543-11e3-aa87-172672d76e00</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 45.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1654.8s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 4 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got retriable error: EmrResponseError: 400 Bad Request\r\n",
        "<ErrorResponse xmlns=\"http://elasticmapreduce.amazonaws.com/doc/2009-03-31\">\r\n",
        "  <Error>\r\n",
        "    <Type>Sender</Type>\r\n",
        "    <Code>Throttling</Code>\r\n",
        "    <Message>Rate exceeded</Message>\r\n",
        "  </Error>\r\n",
        "  <RequestId>5f0c5578-e543-11e3-9423-c97367f9860b</RequestId>\r\n",
        "</ErrorResponse>\r\n",
        "\r\n",
        "Backing off for 20.0 seconds\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1705.7s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 4 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1736.5s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 4 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1767.3s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 4 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1798.1s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 4 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1828.9s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 4 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1859.8s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 4 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1890.7s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 4 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1921.6s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 4 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1952.5s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 4 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 1983.3s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 4 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 2014.2s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 4 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 2045.0s ago, status RUNNING: Running step (weatherPCA.ubuntu.20140527.013707.958277: Step 4 of 4)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job completed.\r\n",
        "Running time was 2037.0s (not counting time spent waiting for the EC2 instances)\r\n",
        "ec2_key_pair_file not specified, going to S3\r\n",
        "Fetching counters from S3...\r\n",
        "Waiting 5.0s for S3 eventual consistency\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters may not have been uploaded to S3 yet. Try again in 5 minutes with: mrjob fetch-logs --counters j-31UKS93V80CN7\r\n",
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "Counters from step 2:\r\n",
        "  (no counters found)\r\n",
        "Counters from step 3:\r\n",
        "  (no counters found)\r\n",
        "Counters from step 4:\r\n",
        "  (no counters found)\r\n",
        "Streaming final output from s3://weiwei.bucket/scratch/weatherPCA.ubuntu.20140527.013707.958277/output/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "removing tmp directory /tmp/weatherPCA.ubuntu.20140527.013707.958277\r\n",
        "Removing all files in s3://weiwei.bucket/scratch/weatherPCA.ubuntu.20140527.013707.958277/\r\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# number of stations with eigen vectors\n",
      "print len(file(\"samplePCA_allnodes.csv\").readlines())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6618\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}