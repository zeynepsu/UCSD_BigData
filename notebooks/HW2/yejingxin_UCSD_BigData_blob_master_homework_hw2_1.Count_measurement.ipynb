{
 "metadata": {
  "name": "",
  "signature": "sha256:32f2728015aec68ff0a310e1e958939ed857d41c8a904fed756495d6ba6b8074"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### This notebook is to use mapreduce filter out the data we want to analyse."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Job flow id management"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys,os\n",
      "cwd=os.getcwd()\n",
      "path=cwd.split('/')\n",
      "home_dir='/'.join(path[:-2])\n",
      "print home_dir\n",
      "sys.path.append(home_dir+'/utils')\n",
      "from find_waiting_flow import *\n",
      "from AWS_keypair_management import *\n",
      "import pickle\n",
      "Creds_file='/home/ubuntu/Vault/Creds.pkl'\n",
      "Creds= pickle.load(open(Creds_file,'rb'))\n",
      "print Creds.keys()\n",
      "print Creds['mrjob'].keys()\n",
      "pair=Creds['mrjob']\n",
      "key_id=pair['key_id']\n",
      "secret_key=pair['secret_key']\n",
      "ID=pair['ID']\n",
      "print ID,key_id\n",
      "job_flow_id=find_waiting_flow(key_id,secret_key)\n",
      "job_flow_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ubuntu/UCSD_BigData\n",
        "['launcher', 'mrjob']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "['key_id', 'secret_key', 's3_logs', 'ID', 's3_scratch']\n",
        "j9ye AKIAJQXNIHPDEKMYISOA\n",
        "<boto.emr.emrobject.JobFlow object at 0x2d37dd0>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " no_script.yoavfreund.20140516.040032.370095 j-262J0JTFJIRLO WAITING\n",
        "<boto.emr.emrobject.JobFlow object at 0x326bc10> no_script.yoavfreund.20140517.080731.371759 j-1RE8D7HBISOI0 WAITING\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "u'j-1RE8D7HBISOI0'"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Here I carry out mapreduce to pick out the data that contains both Tmax and Tmin and more than 200 out of 2*365 days have measurements. Note not all the years have both Tmax and Tmin, it is useful to set [station, year] as key."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_weather.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "count the number of measurements of each type\n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "WORD_RE = re.compile(r\"[\\w']+\")\n",
      "\n",
      "#logfile=open('log','w')\n",
      "#logfile=stderr\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        try:\n",
      "            self.increment_counter('MrJob Counters','mapper-all',1)\n",
      "            elements=line.split(',')\n",
      "            #logfile.write('%s\\n' % type(line))\n",
      "            if elements[1]=='TMAX' or elements[1]=='TMIN':\n",
      "                Ndays = sum([e!='' for e in elements[3:]])\n",
      "                meas = 1\n",
      "                key = (elements[0],elements[2])\n",
      "                #out=(elements[0],elements[2]), \n",
      "            else:\n",
      "                key = ('Useless','Useless')\n",
      "                meas = 0\n",
      "                Ndays = 0\n",
      "        except Exception, e:\n",
      "            stderr.write('Error in line:\\n'+line)\n",
      "            stderr.write(e)\n",
      "            self.increment_counter('MrJob Counters','mapper-error',1)\n",
      "            key = ('error','error')\n",
      "            meas = 0\n",
      "            Ndays = 0\n",
      "\n",
      "        finally:\n",
      "            yield key, (meas,Ndays)\n",
      "\n",
      "            \n",
      "    def combiner(self, word, counts):\n",
      "        self.increment_counter('MrJob Counters','combiner',1)\n",
      "        sum1 = 0\n",
      "        sum2 = 0\n",
      "        for meas,Ndays in counts:\n",
      "            sum1 = sum1 + meas\n",
      "            sum2 = sum2 + Ndays\n",
      "        yield word, (sum1, sum2)\n",
      "\n",
      "    def reducer(self, word, counts):\n",
      "        self.increment_counter('MrJob Counters','reducer',1)\n",
      "        sum1 = 0\n",
      "        sum2 = 0\n",
      "        for meas,Ndays in counts:\n",
      "            sum1 = sum1 + meas\n",
      "            sum2 = sum2 + Ndays\n",
      "        if sum1 == 2 and sum2>200:\n",
      "            yield '%s %s' %(word[0],word[1]), sum2\n",
      "        else:\n",
      "            yield 'Useless Useless',0\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting mr_weather.py\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### small dataset used for debug"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_data='/home/ubuntu/UCSD_BigData/data/weather/ALL.head.csv'\n",
      "!ls -l $local_data\n",
      "!python mr_weather.py -r emr --emr-job-flow-id  $job_flow_id < $local_data > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw-rw-r-- 1 ubuntu ubuntu 858960 May 16 00:53 /home/ubuntu/UCSD_BigData/data/weather/ALL.head.csv\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /tmp/mr_weather.ubuntu.20140522.220647.400856\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "reading from STDIN\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://ye.bucket/weather/scratch/mr_weather.ubuntu.20140522.220647.400856/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding our job to existing job flow j-1RE8D7HBISOI0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 31.0s ago, status RUNNING: Running step (mr_weather.ubuntu.20140522.220647.400856: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 62.0s ago, status RUNNING: Running step (mr_weather.ubuntu.20140522.220647.400856: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 92.9s ago, status RUNNING: Running step (mr_weather.ubuntu.20140522.220647.400856: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 123.7s ago, status RUNNING: Running step (mr_weather.ubuntu.20140522.220647.400856: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job completed.\r\n",
        "Running time was 69.0s (not counting time spent waiting for the EC2 instances)\r\n",
        "ec2_key_pair_file not specified, going to S3\r\n",
        "Fetching counters from S3...\r\n",
        "Waiting 5.0s for S3 eventual consistency\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters may not have been uploaded to S3 yet. Try again in 5 minutes with: mrjob fetch-logs --counters j-1RE8D7HBISOI0\r\n",
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Streaming final output from s3://ye.bucket/weather/scratch/mr_weather.ubuntu.20140522.220647.400856/output/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "removing tmp directory /tmp/mr_weather.ubuntu.20140522.220647.400856\r\n",
        "Removing all files in s3://ye.bucket/weather/scratch/mr_weather.ubuntu.20140522.220647.400856/\r\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -5 counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"MX000008172 1966\"\t704\r\n",
        "\"MX000008172 1977\"\t700\r\n",
        "\"MX000008172 1980\"\t658\r\n",
        "\"MX000008172 1988\"\t723\r\n",
        "\"MX000008172 1991\"\t517\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### preform mapreduce on hdfs large dataset, output is written into Tmax_min_counts.dat"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "job_flow_id='j-262J0JTFJIRLO'#find_waiting_flow(key_id,secret_key)\n",
      "!python mr_weather.py -r emr --emr-job-flow-id $job_flow_id hdfs:/weather/weather.csv > test.dat#Tmax_min_counts.dat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /tmp/mr_weather.ubuntu.20140524.192453.598381\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://ye.bucket/weather/scratch/mr_weather.ubuntu.20140524.192453.598381/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding our job to existing job flow j-262J0JTFJIRLO\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Attempting to terminate job...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traceback (most recent call last):\r\n",
        "  File \"mr_weather.py\", line 66, in <module>\r\n",
        "    MRWeather.run()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/job.py\", line 494, in run\r\n",
        "    mr_job.execute()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/job.py\", line 512, in execute\r\n",
        "    super(MRJob, self).execute()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/launch.py\", line 147, in execute\r\n",
        "    self.run_job()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/launch.py\", line 213, in run_job\r\n",
        "    self.stdout.flush()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/runner.py\", line 614, in __exit__\r\n",
        "    self.cleanup()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/emr.py\", line 1010, in cleanup\r\n",
        "    super(EMRJobRunner, self).cleanup(mode=mode)\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/runner.py\", line 560, in cleanup\r\n",
        "    self._cleanup_job()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/emr.py\", line 1084, in _cleanup_job\r\n",
        "    self._opts['ec2_key_pair_file'])\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/ssh.py\", line 200, in ssh_terminate_single_job\r\n",
        "    ssh_bin, address, ec2_key_pair_file, ['hadoop', 'job', '-list']))\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/ssh.py\", line 82, in ssh_run\r\n",
        "    p = Popen(args, stdout=PIPE, stderr=PIPE, stdin=PIPE)\r\n",
        "  File \"/home/ubuntu/anaconda/lib/python2.7/subprocess.py\", line 709, in __init__\r\n",
        "    errread, errwrite)\r\n",
        "  File \"/home/ubuntu/anaconda/lib/python2.7/subprocess.py\", line 1326, in _execute_child\r\n",
        "    raise child_exception\r\n",
        "TypeError: execv() arg 2 must contain only strings\r\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -10 Tmax_min_counts.dat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"Useless Useless\"\t0\r\n",
        "\"AE000041196 1959\"\t692\r\n",
        "\"AE000041196 1984\"\t568\r\n",
        "\"AE000041196 1995\"\t575\r\n",
        "\"AE000041196 2006\"\t547\r\n",
        "\"Useless Useless\"\t0\r\n",
        "\"Useless Useless\"\t0\r\n",
        "\"AG000060390 1943\"\t724\r\n",
        "\"AG000060390 1954\"\t730\r\n",
        "\"AG000060390 1965\"\t730\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    }
   ],
   "metadata": {}
  }
 ]
}