{
 "metadata": {
  "name": "",
  "signature": "sha256:0894f48516a22664731488757ac1975721d5dc0f9a394ca5be2a2b6110575d15"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      " 1. Ignore stations with no temperature recordings"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sklearn as sk\n",
      "print 'pandas version: ',pd.__version__\n",
      "print 'numpy version:',np.__version__\n",
      "print 'sklearn version:',sk.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pandas version:  0.13.1\n",
        "numpy version: 1.8.1\n",
        "sklearn version: 0.14.1\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "header=['station','measurement','year']+range(1,366)\n",
      "# D=pandas.DataFrame(columns=header)\n",
      "Data = pd.read_csv('/home/ubuntu/UCSD_BigData/data/weather/SAMPLE_TMAX.csv',header=None,names=header)\n",
      "G=Data.ix[:,1:365]\n",
      "G[G<-400]=nan\n",
      "G[G>500]=nan\n",
      "G=G/10\n",
      "Data.ix[:,1:365]=G\n",
      "G=G.transpose()\n",
      "Data.head() ## data is untouched good original data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>station</th>\n",
        "      <th>measurement</th>\n",
        "      <th>year</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "      <th>8</th>\n",
        "      <th>9</th>\n",
        "      <th>10</th>\n",
        "      <th>11</th>\n",
        "      <th>12</th>\n",
        "      <th>13</th>\n",
        "      <th>14</th>\n",
        "      <th>15</th>\n",
        "      <th>16</th>\n",
        "      <th>17</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> USC00507570</td>\n",
        "      <td> TMAX</td>\n",
        "      <td> 2005</td>\n",
        "      <td>  6.7</td>\n",
        "      <td>  4.4</td>\n",
        "      <td>  6.1</td>\n",
        "      <td>  1.7</td>\n",
        "      <td> -1.7</td>\n",
        "      <td> -2.2</td>\n",
        "      <td> -3.9</td>\n",
        "      <td> -4.4</td>\n",
        "      <td> -4.4</td>\n",
        "      <td> -7.8</td>\n",
        "      <td>-15.6</td>\n",
        "      <td>-15.6</td>\n",
        "      <td> -3.3</td>\n",
        "      <td>  2.8</td>\n",
        "      <td>  3.9</td>\n",
        "      <td>  2.2</td>\n",
        "      <td> -8.9</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> NOE00135018</td>\n",
        "      <td> TMAX</td>\n",
        "      <td> 1959</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> KZ000036546</td>\n",
        "      <td> TMAX</td>\n",
        "      <td> 1982</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>-13.9</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> -4.5</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> -2.8</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> -5.5</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> -6.3</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> USC00054664</td>\n",
        "      <td> TMAX</td>\n",
        "      <td> 1964</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> CUW00011706</td>\n",
        "      <td> TMAX</td>\n",
        "      <td> 1981</td>\n",
        "      <td> 30.0</td>\n",
        "      <td> 28.3</td>\n",
        "      <td> 30.0</td>\n",
        "      <td> 30.0</td>\n",
        "      <td> 28.3</td>\n",
        "      <td> 28.9</td>\n",
        "      <td> 28.9</td>\n",
        "      <td> 31.1</td>\n",
        "      <td> 30.0</td>\n",
        "      <td> 29.4</td>\n",
        "      <td> 30.6</td>\n",
        "      <td> 25.6</td>\n",
        "      <td> 23.3</td>\n",
        "      <td> 28.3</td>\n",
        "      <td> 28.9</td>\n",
        "      <td> 30.0</td>\n",
        "      <td> 29.4</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 368 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "       station measurement  year     1     2     3     4     5     6     7  \\\n",
        "0  USC00507570        TMAX  2005   6.7   4.4   6.1   1.7  -1.7  -2.2  -3.9   \n",
        "1  NOE00135018        TMAX  1959   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "2  KZ000036546        TMAX  1982   NaN   NaN -13.9   NaN   NaN  -4.5   NaN   \n",
        "3  USC00054664        TMAX  1964   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "4  CUW00011706        TMAX  1981  30.0  28.3  30.0  30.0  28.3  28.9  28.9   \n",
        "\n",
        "      8     9    10    11    12    13    14    15    16    17      \n",
        "0  -4.4  -4.4  -7.8 -15.6 -15.6  -3.3   2.8   3.9   2.2  -8.9 ...  \n",
        "1   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...  \n",
        "2   NaN  -2.8   NaN  -5.5   NaN  -6.3   NaN   NaN   NaN   NaN ...  \n",
        "3   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...  \n",
        "4  31.1  30.0  29.4  30.6  25.6  23.3  28.3  28.9  30.0  29.4 ...  \n",
        "\n",
        "[5 rows x 368 columns]"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "Data = pd.read_csv('/home/ubuntu/UCSD_BigData/data/weather/ALL.head.csv', header = None)\n",
      "Data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "      <th>8</th>\n",
        "      <th>9</th>\n",
        "      <th>10</th>\n",
        "      <th>11</th>\n",
        "      <th>12</th>\n",
        "      <th>13</th>\n",
        "      <th>14</th>\n",
        "      <th>15</th>\n",
        "      <th>16</th>\n",
        "      <th>17</th>\n",
        "      <th>18</th>\n",
        "      <th>19</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> ASN00054128</td>\n",
        "      <td> DAPR</td>\n",
        "      <td> 1969</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> ASN00054128</td>\n",
        "      <td> DAPR</td>\n",
        "      <td> 1971</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> ASN00054128</td>\n",
        "      <td> DAPR</td>\n",
        "      <td> 1972</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> ASN00054128</td>\n",
        "      <td> DAPR</td>\n",
        "      <td> 1976</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> ASN00054128</td>\n",
        "      <td> DAPR</td>\n",
        "      <td> 1979</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 368 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "            0     1     2   3   4   5   6   7   8   9   10  11  12  13  14  \\\n",
        "0  ASN00054128  DAPR  1969 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   \n",
        "1  ASN00054128  DAPR  1971 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   \n",
        "2  ASN00054128  DAPR  1972 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   \n",
        "3  ASN00054128  DAPR  1976 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   \n",
        "4  ASN00054128  DAPR  1979 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   \n",
        "\n",
        "   15  16  17  18  19      \n",
        "0 NaN NaN NaN NaN NaN ...  \n",
        "1 NaN NaN NaN NaN NaN ...  \n",
        "2 NaN NaN NaN NaN NaN ...  \n",
        "3 NaN NaN NaN NaN NaN ...  \n",
        "4 NaN NaN NaN NaN NaN ...  \n",
        "\n",
        "[5 rows x 368 columns]"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Manage AWS credentials and check available job flow"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "home_dir='/home/ubuntu/UCSD_BigData'\n",
      "sys.path.append(home_dir+'/utils')\n",
      "from find_waiting_flow import *\n",
      "from AWS_keypair_management import *\n",
      "import pickle\n",
      "Creds= pickle.load(open('/home/ubuntu/Vault/Creds.pkl','rb'))\n",
      "print Creds.keys()\n",
      "print Creds['mrjob'].keys()\n",
      "pair=Creds['mrjob']\n",
      "key_id=pair['key_id']\n",
      "secret_key=pair['secret_key']\n",
      "ID=pair['ID']\n",
      "print ID,key_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['launcher', 'mrjob']\n",
        "['key_id', 'secret_key', 's3_logs', 'ID', 's3_scratch']\n",
        "yuw176 AKIAIARNTVMBKC4UZA3Q\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Overwrite the mapreduce function"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, I pick out the stations that have published minimum and maximum measurements in a year, and count the number of years."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_weather.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "count the number of measurements of each type\n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "WORD_RE = re.compile(r\"[\\w']+\")\n",
      "\n",
      "#logfile=open('log','w')\n",
      "#logfile=stderr\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "\n",
      "    def my_mapper(self, _, line):\n",
      "        try:\n",
      "            self.increment_counter('MrJob Counters','my_mapper',1)\n",
      "            elements=line.split(',')\n",
      "            #logfile.write('%s\\n' % type(line))\n",
      "            if elements[1]=='TMAX' or elements[1]=='TMIN':\n",
      "                measure = 1\n",
      "                key = (elements[0],elements[2])\n",
      "            else:\n",
      "                key = ('NA','NA')\n",
      "                measure = 0\n",
      "            n_days = sum([e!='' for e in elements[3:]])\n",
      "\n",
      "        except Exception, e:\n",
      "            stderr.write('Error in line:\\n'+line)\n",
      "            stderr.write(e)\n",
      "            self.increment_counter('MrJob Counters','mapper-error',1)\n",
      "            key = ('error','error')\n",
      "            measure = 0\n",
      "            n_days = 0\n",
      "\n",
      "        finally:\n",
      "            yield key, (measure, n_days)\n",
      "\n",
      "            \n",
      "    def my_combiner(self, word, counts):\n",
      "        self.increment_counter('MrJob Counters','my_combiner',1)\n",
      "        sum1=0\n",
      "        sum2=0\n",
      "        for measure, n_days in counts:\n",
      "            sum1 = sum1 + measure\n",
      "            sum2 = sum2 + n_days\n",
      "        yield word, (sum1,sum2)\n",
      "\n",
      "    def my_reducer1(self, word, counts):\n",
      "        self.increment_counter('MrJob Counters','my_reducer1',1)\n",
      "        sum1 = 0\n",
      "        sum2 = 0\n",
      "        for measure, n_days in counts:\n",
      "            sum1 = sum1 + measure\n",
      "            sum2 = sum2 + n_days\n",
      "        if sum1 ==2:\n",
      "            yield word[0], (word[1], sum2)\n",
      "        else:\n",
      "            yield ('NA'), ('NA', 0)\n",
      "    def my_reducer2(self, word, counts):\n",
      "        self.increment_counter('MrJob Counters','my_reducer2',1)\n",
      "        n_year = 0\n",
      "        for year, n_days in counts:\n",
      "            if n_days>0:\n",
      "                n_year= n_year+1\n",
      "        if n_year == 0:\n",
      "            yield 'NA', 0\n",
      "        else:\n",
      "            yield word, n_year\n",
      "            \n",
      "    def steps(self):\n",
      "        return [self.mr(mapper=self.my_mapper, combiner=self.my_combiner, reducer = self.my_reducer1),\n",
      "                self.mr(reducer=self.my_reducer2)]\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting mr_weather.py\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I use the small dataset to run locally for debug."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_data='/home/ubuntu/UCSD_BigData/data/weather/ALL.head.csv'\n",
      "!python mr_weather.py $local_data > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n",
        "creating tmp directory /tmp/mr_weather.ubuntu.20140527.002019.015136\r\n",
        "writing to /tmp/mr_weather.ubuntu.20140527.002019.015136/step-0-mapper_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  MrJob Counters:\r\n",
        "    my_combiner: 124\r\n",
        "    my_mapper: 999\r\n",
        "writing to /tmp/mr_weather.ubuntu.20140527.002019.015136/step-0-mapper-sorted\r\n",
        "> sort /tmp/mr_weather.ubuntu.20140527.002019.015136/step-0-mapper_part-00000\r\n",
        "writing to /tmp/mr_weather.ubuntu.20140527.002019.015136/step-0-reducer_part-00000\r\n",
        "Counters from step 1:\r\n",
        "  MrJob Counters:\r\n",
        "    my_combiner: 124\r\n",
        "    my_mapper: 999\r\n",
        "    my_reducer1: 124\r\n",
        "writing to /tmp/mr_weather.ubuntu.20140527.002019.015136/step-1-mapper_part-00000\r\n",
        "Counters from step 2:\r\n",
        "  (no counters found)\r\n",
        "writing to /tmp/mr_weather.ubuntu.20140527.002019.015136/step-1-mapper-sorted\r\n",
        "> sort /tmp/mr_weather.ubuntu.20140527.002019.015136/step-1-mapper_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "writing to /tmp/mr_weather.ubuntu.20140527.002019.015136/step-1-reducer_part-00000\r\n",
        "Counters from step 2:\r\n",
        "  MrJob Counters:\r\n",
        "    my_reducer2: 4\r\n",
        "Moving /tmp/mr_weather.ubuntu.20140527.002019.015136/step-1-reducer_part-00000 -> /tmp/mr_weather.ubuntu.20140527.002019.015136/output/part-00000\r\n",
        "Streaming final output from /tmp/mr_weather.ubuntu.20140527.002019.015136/output\r\n",
        "removing tmp directory /tmp/mr_weather.ubuntu.20140527.002019.015136\r\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"MX000008172\"\t45\r\n",
        "\"NA\"\t0\r\n",
        "\"USC00211063\"\t41\r\n",
        "\"USC00500433\"\t20\r\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The results show that there are 3 stations that have published both maximum and minimum temperatures in a year, and the eligible years are from 20 to 45."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_data='/home/ubuntu/UCSD_BigData/data/weather/ALL.head.csv'\n",
      "!ls -l $local_data\n",
      "#job_flow_id = u'j-2KCJE554SGITB'\n",
      "job_flow_id=find_waiting_flow(key_id,secret_key)\n",
      "job_flow_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw-rw-r-- 1 ubuntu ubuntu 858960 May 26 01:45 /home/ubuntu/UCSD_BigData/data/weather/ALL.head.csv\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<boto.emr.emrobject.JobFlow object at 0x6d7eb10> no_script.yoavfreund.20140525.174308.746673 j-LTOJMJ14G840 WAITING\n",
        "<boto.emr.emrobject.JobFlow object at 0x61606d0> no_script.yoavfreund.20140525.194233.003342 j-2KCJE554SGITB WAITING\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "u'j-2KCJE554SGITB'"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then, perform the hdfs datast on EMR"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "job_flow_id=find_waiting_flow(key_id,secret_key)\n",
      "job_flow_id = 'j-2KCJE554SGITB'\n",
      "!python mr_weather.py -r emr --emr-job-flow-id $job_flow_id hdfs:/weather/weather.csv > stations_with_minmax"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<boto.emr.emrobject.JobFlow object at 0x644a510> no_script.yoavfreund.20140525.174308.746673 j-LTOJMJ14G840 WAITING\n",
        "<boto.emr.emrobject.JobFlow object at 0x5f01090> no_script.yoavfreund.20140525.194233.003342 j-2KCJE554SGITB WAITING\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating new scratch bucket mrjob-75c85c5942aa82fa\r\n",
        "using s3://mrjob-75c85c5942aa82fa/tmp/ as our scratch dir on S3\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /tmp/mr_weather.ubuntu.20140527.003102.671962\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating S3 bucket 'mrjob-75c85c5942aa82fa' to use as scratch space\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://mrjob-75c85c5942aa82fa/tmp/mr_weather.ubuntu.20140527.003102.671962/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding our job to existing job flow j-2KCJE554SGITB\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 31.1s ago, status RUNNING: Running step (mr_weather.ubuntu.20140527.003102.671962: Step 1 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 62.3s ago, status RUNNING: Running step (mr_weather.ubuntu.20140527.003102.671962: Step 1 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 93.4s ago, status RUNNING: Running step (mr_weather.ubuntu.20140527.003102.671962: Step 1 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 124.6s ago, status RUNNING: Running step (mr_weather.ubuntu.20140527.003102.671962: Step 1 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 155.7s ago, status RUNNING: Running step (mr_weather.ubuntu.20140527.003102.671962: Step 1 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 186.7s ago, status RUNNING: Running step (mr_weather.ubuntu.20140527.003102.671962: Step 1 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 217.8s ago, status RUNNING: Running step (mr_weather.ubuntu.20140527.003102.671962: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 248.8s ago, status RUNNING: Running step (mr_weather.ubuntu.20140527.003102.671962: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 279.8s ago, status RUNNING: Running step (mr_weather.ubuntu.20140527.003102.671962: Step 2 of 2)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job completed.\r\n",
        "Running time was 256.0s (not counting time spent waiting for the EC2 instances)\r\n",
        "ec2_key_pair_file not specified, going to S3\r\n",
        "Fetching counters from S3...\r\n",
        "Waiting 5.0s for S3 eventual consistency\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters may not have been uploaded to S3 yet. Try again in 5 minutes with: mrjob fetch-logs --counters j-2KCJE554SGITB\r\n",
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "Counters from step 2:\r\n",
        "  (no counters found)\r\n",
        "Streaming final output from s3://mrjob-75c85c5942aa82fa/tmp/mr_weather.ubuntu.20140527.003102.671962/output/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "removing tmp directory /tmp/mr_weather.ubuntu.20140527.003102.671962\r\n",
        "Removing all files in s3://mrjob-75c85c5942aa82fa/tmp/mr_weather.ubuntu.20140527.003102.671962/\r\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The top 20 results are as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -20 stations_with_minmax"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"AJ000037756\"\t19\r\n",
        "\"AJ000037844\"\t21\r\n",
        "\"AJ000037866\"\t24\r\n",
        "\"AJ000037899\"\t16\r\n",
        "\"AJ000037907\"\t40\r\n",
        "\"AM000037704\"\t15\r\n",
        "\"AQC00914873\"\t12\r\n",
        "\"AR000087270\"\t53\r\n",
        "\"AR000087344\"\t56\r\n",
        "\"AR000087418\"\t55\r\n",
        "\"AR000087715\"\t58\r\n",
        "\"AR000087803\"\t54\r\n",
        "\"AR000870470\"\t49\r\n",
        "\"ASN00001019\"\t15\r\n",
        "\"ASN00002012\"\t69\r\n",
        "\"ASN00002056\"\t27\r\n",
        "\"ASN00003002\"\t57\r\n",
        "\"ASN00003057\"\t28\r\n",
        "\"ASN00003093\"\t16\r\n",
        "\"ASN00004083\"\t20\r\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}