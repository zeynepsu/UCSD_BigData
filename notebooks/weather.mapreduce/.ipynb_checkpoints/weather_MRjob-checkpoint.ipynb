{
 "metadata": {
  "name": "",
  "signature": "sha256:7d1a3d3d874e7d088eb3d6610b1df9a70243b4cb98a4d622c0deceeda8ee2a14"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sklearn as sk\n",
      "print 'pandas version: ',pd.__version__\n",
      "print 'numpy version:',np.__version__\n",
      "print 'sklearn version:',sk.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pandas version:  0.13.1\n",
        "numpy version: 1.8.1\n",
        "sklearn version: 0.14.1\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "home_dir='/home/ubuntu/UCSD_BigData'\n",
      "data_dir=home_dir+'/data/weather'\n",
      "!ls $data_dir\n",
      "!pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ALL.head.csv\t  ghcnd-stations_buffered.txt  SAMPLE_TMAX.csv\r\n",
        "data-source.txt   ghcnd-stations.txt\t       SAMPLE_TMAX.csv.old.gz\r\n",
        "ghcnd-readme.txt  ghcnd-version.txt\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ubuntu/UCSD_BigData/notebooks/weather.mapreduce\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/bin/env python\n",
      "import os,sys,re,pickle,coding\n",
      "from numpy import *\n",
      "\n",
      "!gunzip stations.pkl.gz\n",
      "stations=pickle.load(open('stations.pkl', 'rb'))\n",
      "!gzip stations.pkl\n",
      "\n",
      "#Days=pickle.load(open('Dates.pkl', 'rb'))\n",
      "\n",
      "stations.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>latitude</th>\n",
        "      <th>longitude</th>\n",
        "      <th>elevation</th>\n",
        "      <th>state</th>\n",
        "      <th>name</th>\n",
        "      <th>GSNFLAG</th>\n",
        "      <th>HCNFLAG</th>\n",
        "      <th>WMOID</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>ACW00011604</th>\n",
        "      <td> 17.1167</td>\n",
        "      <td>-61.7833</td>\n",
        "      <td>   10.1</td>\n",
        "      <td> NaN</td>\n",
        "      <td> ST JOHNS COOLIDGE FLD</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>   NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ACW00011647</th>\n",
        "      <td> 17.1333</td>\n",
        "      <td>-61.7833</td>\n",
        "      <td>   19.2</td>\n",
        "      <td> NaN</td>\n",
        "      <td>              ST JOHNS</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>   NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AE000041196</th>\n",
        "      <td> 25.3330</td>\n",
        "      <td> 55.5170</td>\n",
        "      <td>   34.0</td>\n",
        "      <td> NaN</td>\n",
        "      <td>   SHARJAH INTER. AIRP</td>\n",
        "      <td> GSN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 41196</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AF000040930</th>\n",
        "      <td> 35.3170</td>\n",
        "      <td> 69.0170</td>\n",
        "      <td> 3366.0</td>\n",
        "      <td> NaN</td>\n",
        "      <td>          NORTH-SALANG</td>\n",
        "      <td> GSN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 40930</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AG000060390</th>\n",
        "      <td> 36.7167</td>\n",
        "      <td>  3.2500</td>\n",
        "      <td>   24.0</td>\n",
        "      <td> NaN</td>\n",
        "      <td>    ALGER-DAR EL BEIDA</td>\n",
        "      <td> GSN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 60390</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 8 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "             latitude  longitude  elevation state                   name  \\\n",
        "ACW00011604   17.1167   -61.7833       10.1   NaN  ST JOHNS COOLIDGE FLD   \n",
        "ACW00011647   17.1333   -61.7833       19.2   NaN               ST JOHNS   \n",
        "AE000041196   25.3330    55.5170       34.0   NaN    SHARJAH INTER. AIRP   \n",
        "AF000040930   35.3170    69.0170     3366.0   NaN           NORTH-SALANG   \n",
        "AG000060390   36.7167     3.2500       24.0   NaN     ALGER-DAR EL BEIDA   \n",
        "\n",
        "            GSNFLAG HCNFLAG  WMOID  \n",
        "ACW00011604     NaN     NaN    NaN  \n",
        "ACW00011647     NaN     NaN    NaN  \n",
        "AE000041196     GSN     NaN  41196  \n",
        "AF000040930     GSN     NaN  40930  \n",
        "AG000060390     GSN     NaN  60390  \n",
        "\n",
        "[5 rows x 8 columns]"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append(home_dir+'/utils')\n",
      "!ls $home_dir/utils\n",
      "!grep def $home_dir/utils/*.py\n",
      "from AWS_keypair_management import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AWS_keypair_management.py   find_waiting_flow.py\r\n",
        "AWS_keypair_management.pyc  find_waiting_flow.pyc\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ubuntu/UCSD_BigData/utils/AWS_keypair_management.py:def test_key_pair(Access_Key_Id,Secret_Access_Key):\r\n",
        "/home/ubuntu/UCSD_BigData/utils/AWS_keypair_management.py:def Get_Working_Credentials(path):\r\n",
        "/home/ubuntu/UCSD_BigData/utils/find_waiting_flow.py:def find_waiting_flow(aws_access_key_id,aws_secret_access_key):\r\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Get_Working_Credentials('~/vault')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "OSError",
       "evalue": "[Errno 2] No such file or directory: '~/vault'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-26-0a4352ee9668>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mGet_Working_Credentials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'~/vault'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/home/ubuntu/UCSD_BigData/utils/AWS_keypair_management.py\u001b[0m in \u001b[0;36mGet_Working_Credentials\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mof\u001b[0m \u001b[0mthese\u001b[0m \u001b[0mAWS\u001b[0m \u001b[0mkey\u001b[0m \u001b[0mpairs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mactive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \"\"\"\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mcredentials_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'User Name,Access Key Id,Secret Access Key'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mKey_Table\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mOSError\u001b[0m: [Errno 2] No such file or directory: '~/vault'"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -2 $data_dir/ALL.head.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "station,year,measurement,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365\r\n",
        "ASN00054128,DAPR,1969,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\r\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cp ../mrjob/mr_word_freq_counters.py mr_weather.py\n",
      "%load mr_weather.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_weather.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "count the number of measurements of each type\n",
      "\"\"\"\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "#logfile=open('log','w')\n",
      "logfile=stderr\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        self.increment_counter('MrJob Counters','mapper',1)\n",
      "        elements=line.split(',')\n",
      "        if elements[0]=='station':\n",
      "            yield('header',1)\n",
      "        else:\n",
      "            yield(elements[1],1)\n",
      "            \n",
      "    def combiner(self, word, counts):\n",
      "        self.increment_counter('MrJob Counters','combiner',1)\n",
      "        yield (word, sum(counts))\n",
      "        #l_counts=[c for c in counts]  # extract list from iterator\n",
      "        #S=sum(l_counts)\n",
      "        #logfile.write('combiner '+word+' ['+','.join([str(c) for c in l_counts])+']='+str(S)+'\\n')\n",
      "        #yield (word, S)\n",
      "\n",
      "    def reducer(self, word, counts):\n",
      "        self.increment_counter('MrJob Counters','reducer',1)\n",
      "        yield (word, sum(counts))\n",
      "        #l_counts=[c for c in counts]  # extract list from iterator\n",
      "        #S=sum(l_counts)\n",
      "        #logfile.write('reducer '+word+' ['+','.join([str(c) for c in l_counts])+']='+str(S)+'\\n')\n",
      "        #yield (word, S)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting mr_weather.py\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_weather.py /Users/yoavfreund/BigData/UCSD_BigData/data/weather/ALL.head.csv > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /Users/yoavfreund/.mrjob.conf\r\n",
        "creating tmp directory /var/folders/80/c2kfvdvx5cx570r4vlzqgb840000gq/T/mr_weather.yoavfreund.20140508.201508.979166\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "writing to /var/folders/80/c2kfvdvx5cx570r4vlzqgb840000gq/T/mr_weather.yoavfreund.20140508.201508.979166/step-0-mapper_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  MrJob Counters:\r\n",
        "    combiner: 22\r\n",
        "    mapper: 1000\r\n",
        "writing to /var/folders/80/c2kfvdvx5cx570r4vlzqgb840000gq/T/mr_weather.yoavfreund.20140508.201508.979166/step-0-mapper-sorted\r\n",
        "> sort /var/folders/80/c2kfvdvx5cx570r4vlzqgb840000gq/T/mr_weather.yoavfreund.20140508.201508.979166/step-0-mapper_part-00000\r\n",
        "writing to /var/folders/80/c2kfvdvx5cx570r4vlzqgb840000gq/T/mr_weather.yoavfreund.20140508.201508.979166/step-0-reducer_part-00000\r\n",
        "Counters from step 1:\r\n",
        "  MrJob Counters:\r\n",
        "    combiner: 22\r\n",
        "    mapper: 1000\r\n",
        "    reducer: 22\r\n",
        "Moving /var/folders/80/c2kfvdvx5cx570r4vlzqgb840000gq/T/mr_weather.yoavfreund.20140508.201508.979166/step-0-reducer_part-00000 -> /var/folders/80/c2kfvdvx5cx570r4vlzqgb840000gq/T/mr_weather.yoavfreund.20140508.201508.979166/output/part-00000\r\n",
        "Streaming final output from /var/folders/80/c2kfvdvx5cx570r4vlzqgb840000gq/T/mr_weather.yoavfreund.20140508.201508.979166/output\r\n",
        "removing tmp directory /var/folders/80/c2kfvdvx5cx570r4vlzqgb840000gq/T/mr_weather.yoavfreund.20140508.201508.979166\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"DAPR\"\t29\r\n",
        "\"DASF\"\t3\r\n",
        "\"DWPR\"\t17\r\n",
        "\"MDPR\"\t37\r\n",
        "\"MDSF\"\t5\r\n",
        "\"PRCP\"\t420\r\n",
        "\"SNOW\"\t83\r\n",
        "\"SNWD\"\t85\r\n",
        "\"TMAX\"\t123\r\n",
        "\"TMIN\"\t106\r\n",
        "\"TOBS\"\t45\r\n",
        "\"WT01\"\t12\r\n",
        "\"WT03\"\t7\r\n",
        "\"WT04\"\t5\r\n",
        "\"WT05\"\t2\r\n",
        "\"WT06\"\t3\r\n",
        "\"WT08\"\t2\r\n",
        "\"WT11\"\t3\r\n",
        "\"WT14\"\t4\r\n",
        "\"WT16\"\t5\r\n",
        "\"WT18\"\t3\r\n",
        "\"header\"\t1\r\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%load $data_dir/ghcnd-readme.txt\n",
      "#after loading - restricted to part that describes the the measurement types"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "ELEMENT    is the element type.   There are five core elements as well as a number\n",
      "           of addition elements.  \n",
      "\t   \n",
      "\t   The five core elements are:\n",
      "\n",
      "       PRCP = Precipitation (tenths of mm)\n",
      "       SNOW = Snowfall (mm)\n",
      "\t   SNWD = Snow depth (mm)\n",
      "       TMAX = Maximum temperature (tenths of degrees C)\n",
      "       TMIN = Minimum temperature (tenths of degrees C)\n",
      "\t   \n",
      "\t   The other elements are:\n",
      "\t   \n",
      "\t   ACMC = Average cloudiness midnight to midnight from 30-second \n",
      "\t          ceilometer data (percent)\n",
      "\t   ACMH = Average cloudiness midnight to midnight from \n",
      "\t          manual observations (percent)\n",
      "           ACSC = Average cloudiness sunrise to sunset from 30-second \n",
      "\t          ceilometer data (percent)\n",
      "\t   ACSH = Average cloudiness sunrise to sunset from manual \n",
      "\t          observations (percent)\n",
      "\t   AWND = Average daily wind speed (tenths of meters per second)\n",
      "\t   DAEV = Number of days included in the multiday evaporation\n",
      "\t          total (MDEV)\n",
      "\t   DAPR = Number of days included in the multiday precipiation \n",
      "\t          total (MDPR)\n",
      "           DASF = Number of days included in the multiday snowfall \n",
      "\t          total (MDSF)\t\t  \n",
      "\t   DATN = Number of days included in the multiday minimum temperature \n",
      "\t         (MDTN)\n",
      "\t   DATX = Number of days included in the multiday maximum temperature \n",
      "\t          (MDTX)\n",
      "           DAWM = Number of days included in the multiday wind movement\n",
      "\t          (MDWM)\n",
      "\t   DWPR = Number of days with non-zero precipitation included in \n",
      "\t          multiday precipitation total (MDPR)\n",
      "\t   EVAP = Evaporation of water from evaporation pan (tenths of mm)\n",
      "\t   FMTM = Time of fastest mile or fastest 1-minute wind \n",
      "\t          (hours and minutes, i.e., HHMM)\n",
      "\t   FRGB = Base of frozen ground layer (cm)\n",
      "\t   FRGT = Top of frozen ground layer (cm)\n",
      "\t   FRTH = Thickness of frozen ground layer (cm)\n",
      "\t   GAHT = Difference between river and gauge height (cm)\n",
      "\t   MDEV = Multiday evaporation total (tenths of mm; use with DAEV)\n",
      "\t   MDPR = Multiday precipitation total (tenths of mm; use with DAPR and \n",
      "\t          DWPR, if available)\n",
      "\t   MDSF = Multiday snowfall total \n",
      "\t   MDTN = Multiday minimum temperature (tenths of degrees C; use with \n",
      "\t          DATN)\n",
      "\t   MDTX = Multiday maximum temperature (tenths of degress C; use with \n",
      "\t          DATX)\n",
      "\t   MDWM = Multiday wind movement (km)\n",
      "           MNPN = Daily minimum temperature of water in an evaporation pan \n",
      "\t         (tenths of degrees C)\n",
      "           MXPN = Daily maximum temperature of water in an evaporation pan \n",
      "\t         (tenths of degrees C)\n",
      "\t   PGTM = Peak gust time (hours and minutes, i.e., HHMM)\n",
      "\t   PSUN = Daily percent of possible sunshine (percent)\n",
      "\t   SN*# = Minimum soil temperature (tenths of degrees C)\n",
      "\t          where * corresponds to a code\n",
      "\t          for ground cover and # corresponds to a code for soil \n",
      "\t\t  depth.  \n",
      "\t\t  \n",
      "\t\t  Ground cover codes include the following:\n",
      "\t\t  0 = unknown\n",
      "\t\t  1 = grass\n",
      "\t\t  2 = fallow\n",
      "\t\t  3 = bare ground\n",
      "\t\t  4 = brome grass\n",
      "\t\t  5 = sod\n",
      "\t\t  6 = straw multch\n",
      "\t\t  7 = grass muck\n",
      "\t\t  8 = bare muck\n",
      "\t\t  \n",
      "\t\t  Depth codes include the following:\n",
      "\t\t  1 = 5 cm\n",
      "\t\t  2 = 10 cm\n",
      "\t\t  3 = 20 cm\n",
      "\t\t  4 = 50 cm\n",
      "\t\t  5 = 100 cm\n",
      "\t\t  6 = 150 cm\n",
      "\t\t  7 = 180 cm\n",
      "\t\t  \n",
      "\t   SX*# = Maximum soil temperature (tenths of degrees C) \n",
      "\t          where * corresponds to a code for ground cover \n",
      "\t\t  and # corresponds to a code for soil depth. \n",
      "\t\t  See SN*# for ground cover and depth codes. \n",
      "\n",
      "           THIC = Thickness of ice on water (tenths of mm)\t\n",
      " \t   TOBS = Temperature at the time of observation (tenths of degrees C)\n",
      "\t   TSUN = Daily total sunshine (minutes)\n",
      "\t   WDF1 = Direction of fastest 1-minute wind (degrees)\n",
      "\t   WDF2 = Direction of fastest 2-minute wind (degrees)\n",
      "\t   WDF5 = Direction of fastest 5-second wind (degrees)\n",
      "\t   WDFG = Direction of peak wind gust (degrees)\n",
      "\t   WDFI = Direction of highest instantaneous wind (degrees)\n",
      "\t   WDFM = Fastest mile wind direction (degrees)\n",
      "           WDMV = 24-hour wind movement (km)\t   \n",
      "           WESD = Water equivalent of snow on the ground (tenths of mm)\n",
      "\t   WESF = Water equivalent of snowfall (tenths of mm)\n",
      "\t   WSF1 = Fastest 1-minute wind speed (tenths of meters per second)\n",
      "\t   WSF2 = Fastest 2-minute wind speed (tenths of meters per second)\n",
      "\t   WSF5 = Fastest 5-second wind speed (tenths of meters per second)\n",
      "\t   WSFG = Peak guest wind speed (tenths of meters per second)\n",
      "\t   WSFI = Highest instantaneous wind speed (tenths of meters per second)\n",
      "\t   WSFM = Fastest mile wind speed (tenths of meters per second)\n",
      "\t   WT** = Weather Type where ** has one of the following values:\n",
      "\t   \n",
      "                  01 = Fog, ice fog, or freezing fog (may include heavy fog)\n",
      "                  02 = Heavy fog or heaving freezing fog (not always \n",
      "\t\t       distinquished from fog)\n",
      "                  03 = Thunder\n",
      "                  04 = Ice pellets, sleet, snow pellets, or small hail \n",
      "                  05 = Hail (may include small hail)\n",
      "                  06 = Glaze or rime \n",
      "                  07 = Dust, volcanic ash, blowing dust, blowing sand, or \n",
      "\t\t       blowing obstruction\n",
      "                  08 = Smoke or haze \n",
      "                  09 = Blowing or drifting snow\n",
      "                  10 = Tornado, waterspout, or funnel cloud \n",
      "                  11 = High or damaging winds\n",
      "                  12 = Blowing spray\n",
      "                  13 = Mist\n",
      "                  14 = Drizzle\n",
      "                  15 = Freezing drizzle \n",
      "                  16 = Rain (may include freezing rain, drizzle, and\n",
      "\t\t       freezing drizzle) \n",
      "                  17 = Freezing rain \n",
      "                  18 = Snow, snow pellets, snow grains, or ice crystals\n",
      "                  19 = Unknown source of precipitation \n",
      "                  21 = Ground fog \n",
      "                  22 = Ice fog or freezing fog\n",
      "\t\t  \n",
      "            WV** = Weather in the Vicinity where ** has one of the following \n",
      "\t           values:\n",
      "\t\t   \n",
      "\t\t   01 = Fog, ice fog, or freezing fog (may include heavy fog)\n",
      "\t\t   03 = Thunder\n",
      "\t\t   07 = Ash, dust, sand, or other blowing obstruction\n",
      "\t\t   18 = Snow or ice crystals\n",
      "\t\t   20 = Rain or snow shower\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "job_flow_id='j-BPX1DCPJZHBT'\n",
      "#!python mr_weather.py -r emr  --emr-job-flow-id=$job_flow_id hdfs:/weather/weather.csv > counts\n",
      "!python mr_weather.py -r emr  --emr-job-flow-id=$job_flow_id hdfs:/weather/weather.csv > counts\n",
      "#!python mr_weather.py -r emr -c /Users/yoavfreund/BigData/mrjob/Student_Config --emr-job-flow-id=$job_flow_id hdfs:/weather/weather.csv > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /Users/yoavfreund/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /var/folders/80/c2kfvdvx5cx570r4vlzqgb840000gq/T/mr_weather.yoavfreund.20140511.164825.100696\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://yoav.hadoop/scratch/mr_weather.yoavfreund.20140511.164825.100696/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding our job to existing job flow j-BPX1DCPJZHBT\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 120.8s ago, status RUNNING: Running step (mr_weather.ubuntu.20140510.010427.343724: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 150.9s ago, status RUNNING: Running step (mr_weather.ubuntu.20140510.010427.343724: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job completed.\r\n",
        "Running time was 128.0s (not counting time spent waiting for the EC2 instances)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching counters from S3...\r\n",
        "Waiting 5.0s for S3 eventual consistency\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  File Input Format Counters :\r\n",
        "    Bytes Read: 7670826853\r\n",
        "  File Output Format Counters :\r\n",
        "    Bytes Written: 1529\r\n",
        "  FileSystemCounters:\r\n",
        "    FILE_BYTES_READ: 25065\r\n",
        "    FILE_BYTES_WRITTEN: 1975323\r\n",
        "    HDFS_BYTES_READ: 7670832733\r\n",
        "    S3_BYTES_WRITTEN: 1529\r\n",
        "  Job Counters :\r\n",
        "    Data-local map tasks: 56\r\n",
        "    Launched map tasks: 60\r\n",
        "    Launched reduce tasks: 12\r\n",
        "    Rack-local map tasks: 4\r\n",
        "    SLOTS_MILLIS_MAPS: 2291664\r\n",
        "    SLOTS_MILLIS_REDUCES: 263038\r\n",
        "    Total time spent by all maps waiting after reserving slots (ms): 0\r\n",
        "    Total time spent by all reduces waiting after reserving slots (ms): 0\r\n",
        "  Map-Reduce Framework:\r\n",
        "    CPU time spent (ms): 1062890\r\n",
        "    Combine input records: 9358394\r\n",
        "    Combine output records: 5078\r\n",
        "    Map input bytes: 7668888728\r\n",
        "    Map input records: 9358394\r\n",
        "    Map output bytes: 84225546\r\n",
        "    Map output materialized bytes: 68458\r\n",
        "    Map output records: 9358394\r\n",
        "    Physical memory (bytes) snapshot: 29480972288\r\n",
        "    Reduce input groups: 133\r\n",
        "    Reduce input records: 5078\r\n",
        "    Reduce output records: 133\r\n",
        "    Reduce shuffle bytes: 68458\r\n",
        "    SPLIT_RAW_BYTES: 5880\r\n",
        "    Spilled Records: 10156\r\n",
        "    Total committed heap usage (bytes): 27964473344\r\n",
        "    Virtual memory (bytes) snapshot: 126893780992\r\n",
        "  MrJob Counters:\r\n",
        "    mapper: 9358394\r\n",
        "    reducer: 133\r\n",
        "Streaming final output from s3://yoav.hadoop/scratch/mr_weather.ubuntu.20140510.010427.343724/output/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "removing tmp directory /tmp/mr_weather.ubuntu.20140510.010427.343724\r\n",
        "Removing all files in s3://yoav.hadoop/scratch/mr_weather.ubuntu.20140510.010427.343724/\r\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"DATX\"\t6001\r\n",
        "\"FRGT\"\t282\r\n",
        "\"MDPR\"\t349252\r\n",
        "\"MDTN\"\t6162\r\n",
        "\"MXPN\"\t13698\r\n",
        "\"SN31\"\t357\r\n",
        "\"SN53\"\t125\r\n",
        "\"SX15\"\t2\r\n",
        "\"SX51\"\t108\r\n",
        "\"WDF2\"\t13658\r\n",
        "\"WESF\"\t31503\r\n",
        "\"WT04\"\t163690\r\n",
        "\"WT15\"\t4392\r\n",
        "\"ACMC\"\t13\r\n",
        "\"DASF\"\t17195\r\n",
        "\"EVAP\"\t24827\r\n",
        "\"FMTM\"\t13372\r\n",
        "\"FRTH\"\t135\r\n",
        "\"MDEV\"\t10851\r\n",
        "\"PGTM\"\t26220\r\n",
        "\"SN52\"\t936\r\n",
        "\"SNWD\"\t864192\r\n",
        "\"SX03\"\t752\r\n",
        "\"SX14\"\t3\r\n",
        "\"SX36\"\t7\r\n",
        "\"SX61\"\t23\r\n",
        "\"SX72\"\t9\r\n",
        "\"SX83\"\t9\r\n",
        "\"TMAX\"\t967931\r\n",
        "\"TSUN\"\t10557\r\n",
        "\"WDF1\"\t5319\r\n",
        "\"WDFI\"\t72\r\n",
        "\"WSF2\"\t13657\r\n",
        "\"WT03\"\t272406\r\n",
        "\"WT14\"\t38369\r\n",
        "\"WV01\"\t397\r\n",
        "\"ACSH\"\t9172\r\n",
        "\"DAPR\"\t299139\r\n",
        "\"DATN\"\t6162\r\n",
        "\"FRGB\"\t113\r\n",
        "\"MNPN\"\t13664\r\n",
        "\"PRCP\"\t2521007\r\n",
        "\"SN51\"\t108\r\n",
        "\"SX02\"\t3373\r\n",
        "\"SX13\"\t60\r\n",
        "\"SX35\"\t22\r\n",
        "\"SX82\"\t9\r\n",
        "\"WESD\"\t55740\r\n",
        "\"WSF1\"\t5344\r\n",
        "\"WSFI\"\t77\r\n",
        "\"WT02\"\t22199\r\n",
        "\"WT13\"\t7208\r\n",
        "\"DAEV\"\t10849\r\n",
        "\"GAHT\"\t936\r\n",
        "\"SN03\"\t750\r\n",
        "\"SN14\"\t2\r\n",
        "\"SN36\"\t5\r\n",
        "\"SN61\"\t22\r\n",
        "\"SN72\"\t9\r\n",
        "\"SN83\"\t9\r\n",
        "\"SX01\"\t570\r\n",
        "\"SX12\"\t416\r\n",
        "\"SX23\"\t27\r\n",
        "\"SX34\"\t12\r\n",
        "\"SX56\"\t2\r\n",
        "\"SX81\"\t9\r\n",
        "\"THIC\"\t452\r\n",
        "\"TMIN\"\t969579\r\n",
        "\"WDFG\"\t13759\r\n",
        "\"WDMV\"\t24052\r\n",
        "\"WT01\"\t239625\r\n",
        "\"WT09\"\t28469\r\n",
        "\"WT12\"\t84\r\n",
        "\"WV07\"\t63\r\n",
        "\"WV18\"\t15\r\n",
        "\"ACMH\"\t7960\r\n",
        "\"DWPR\"\t180462\r\n",
        "\"MDWM\"\t8429\r\n",
        "\"SN02\"\t3374\r\n",
        "\"SN13\"\t60\r\n",
        "\"SN35\"\t18\r\n",
        "\"SN82\"\t9\r\n",
        "\"SX11\"\t38\r\n",
        "\"SX22\"\t32\r\n",
        "\"SX33\"\t372\r\n",
        "\"SX55\"\t23\r\n",
        "\"WSFG\"\t14486\r\n",
        "\"WT08\"\t53648\r\n",
        "\"WT11\"\t120277\r\n",
        "\"WT19\"\t4631\r\n",
        "\"WT22\"\t5469\r\n",
        "\"WV20\"\t604\r\n",
        "\"AWND\"\t17950\r\n",
        "\"PSUN\"\t3322\r\n",
        "\"SN01\"\t571\r\n",
        "\"SN12\"\t416\r\n",
        "\"SN23\"\t27\r\n",
        "\"SN34\"\t11\r\n",
        "\"SN56\"\t2\r\n",
        "\"SN81\"\t9\r\n",
        "\"SX21\"\t29\r\n",
        "\"SX32\"\t2405\r\n",
        "\"SX54\"\t20\r\n",
        "\"TOBS\"\t478981\r\n",
        "\"WDF5\"\t13480\r\n",
        "\"WDFM\"\t3201\r\n",
        "\"WT07\"\t19440\r\n",
        "\"WT10\"\t2268\r\n",
        "\"WT18\"\t53072\r\n",
        "\"WT21\"\t2382\r\n",
        "\"DAWM\"\t8428\r\n",
        "\"MDTX\"\t6001\r\n",
        "\"SN11\"\t38\r\n",
        "\"SN22\"\t29\r\n",
        "\"SN33\"\t371\r\n",
        "\"SN55\"\t20\r\n",
        "\"SNOW\"\t881399\r\n",
        "\"SX17\"\t2\r\n",
        "\"SX31\"\t357\r\n",
        "\"SX53\"\t124\r\n",
        "\"WSF5\"\t13482\r\n",
        "\"WSFM\"\t3204\r\n",
        "\"WT06\"\t103479\r\n",
        "\"WT17\"\t6945\r\n",
        "\"ACSC\"\t14\r\n",
        "\"MDSF\"\t20365\r\n",
        "\"SN21\"\t28\r\n",
        "\"SN32\"\t2405\r\n",
        "\"SN54\"\t20\r\n",
        "\"SX52\"\t941\r\n",
        "\"WT05\"\t148289\r\n",
        "\"WT16\"\t73840\r\n",
        "\"WV03\"\t1540\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Two useful command-line utilities"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "the mrjob command line depends on the same configuration file as the run-time library. This configuration file is, by default, located at ~/.mrjob.conf"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!mrjob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "usage: mrjob {subcommand|--help}\"\r\n",
        "\r\n",
        "subcommands:\r\n",
        "  audit-emr-usage:          Audit EMR usage\r\n",
        "  create-job-flow:          Create an EMR job flow\r\n",
        "  fetch-logs:               Fetch and parse EMR logs for errors and counters\r\n",
        "  report-long-jobs:         Report EMR jobs which have been running for a long time\r\n",
        "  run:                      Run a job\r\n",
        "  s3-tmpwatch:              Delete S3 keys older than a specified time\r\n",
        "  terminate-idle-job-flows: Terminate idle EMR job flows\r\n",
        "  terminate-job-flow:       Terminate a single EMR job flow\r\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!mrjob audit-emr-usage"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "getting job flow history...\r\n",
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "compiling job flow stats...\r\n",
        "Total  # of Job Flows: 17\r\n",
        "\r\n",
        "* All times are in UTC.\r\n",
        "\r\n",
        "Min create time: 2014-05-04 05:33:15\r\n",
        "Max create time: 2014-05-09 13:19:58\r\n",
        "   Current time: 2014-05-10 01:01:31\r\n",
        "\r\n",
        "* All usage is measured in Normalized Instance Hours, which are\r\n",
        "  roughly equivalent to running an m1.small instance for an hour.\r\n",
        "  Billing is estimated, and may not match Amazon's system exactly.\r\n",
        "\r\n",
        "Total billed:    1662.08  100.0%\r\n",
        "  Total used:      25.65    1.5%\r\n",
        "    bootstrap:      5.53    0.3%\r\n",
        "    jobs:          20.12    1.2%\r\n",
        "  Total waste:   1636.43   98.5%\r\n",
        "    at end:       494.39   29.7%\r\n",
        "    other:       1142.04   68.7%\r\n",
        "\r\n",
        "Daily statistics:\r\n",
        "\r\n",
        " date          billed      used     waste   % waste\r\n",
        " 2014-05-10     31.70      3.36     28.34      89.4\r\n",
        " 2014-05-09    397.09     15.47    381.62      96.1\r\n",
        " 2014-05-08    573.37      1.93    571.45      99.7\r\n",
        " 2014-05-07    314.41      1.30    313.11      99.6\r\n",
        " 2014-05-06     48.50      0.66     47.85      98.6\r\n",
        " 2014-05-05    206.35      0.00    206.35     100.0\r\n",
        " 2014-05-04     90.65      2.95     87.70      96.8\r\n",
        "\r\n",
        "Hourly statistics:\r\n",
        "\r\n",
        " hour              billed      used     waste   % waste\r\n",
        " 2014-05-10 01       0.78      0.00      0.78     100.0\r\n",
        " 2014-05-10 00      30.92      3.36     27.56      89.1\r\n",
        " 2014-05-09 23      30.92      8.73     22.19      71.8\r\n",
        " 2014-05-09 22      30.92      0.88     30.04      97.2\r\n",
        " 2014-05-09 21      30.92      0.00     30.92     100.0\r\n",
        " 2014-05-09 20      30.92      0.00     30.92     100.0\r\n",
        " 2014-05-09 19      30.92      1.10     29.82      96.4\r\n",
        " 2014-05-09 18      30.92      0.00     30.92     100.0\r\n",
        " 2014-05-09 17      30.92      1.15     29.77      96.3\r\n",
        " 2014-05-09 16      30.92      1.19     29.72      96.1\r\n",
        " 2014-05-09 15      30.92      0.00     30.92     100.0\r\n",
        " 2014-05-09 14      30.92      0.62     30.30      98.0\r\n",
        " 2014-05-09 13      17.21      0.38     16.83      97.8\r\n",
        " 2014-05-09 12       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-09 11       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-09 10       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-09 09       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-09 08       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-09 07       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-09 06       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-09 05       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-09 04       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-09 03       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-09 02      13.71      0.00     13.71     100.0\r\n",
        " 2014-05-09 01      28.67      0.00     28.67     100.0\r\n",
        " 2014-05-09 00      28.33      1.43     26.91      95.0\r\n",
        " 2014-05-08 23      28.00      0.00     28.00     100.0\r\n",
        " 2014-05-08 22      28.00      0.00     28.00     100.0\r\n",
        " 2014-05-08 21      28.00      0.00     28.00     100.0\r\n",
        " 2014-05-08 20      28.00      0.00     28.00     100.0\r\n",
        " 2014-05-08 19      28.00      0.00     28.00     100.0\r\n",
        " 2014-05-08 18      28.00      0.00     28.00     100.0\r\n",
        " 2014-05-08 17      28.00      0.00     28.00     100.0\r\n",
        " 2014-05-08 16      28.00      0.00     28.00     100.0\r\n",
        " 2014-05-08 15      28.28      0.00     28.28     100.0\r\n",
        " 2014-05-08 14      28.72      0.07     28.65      99.8\r\n",
        " 2014-05-08 13      28.00      0.00     28.00     100.0\r\n",
        " 2014-05-08 12      28.00      0.00     28.00     100.0\r\n",
        " 2014-05-08 11      28.00      0.00     28.00     100.0\r\n",
        " 2014-05-08 10      28.00      0.00     28.00     100.0\r\n",
        " 2014-05-08 09      28.00      0.00     28.00     100.0\r\n",
        " 2014-05-08 08      28.00      0.00     28.00     100.0\r\n",
        " 2014-05-08 07      28.00      0.00     28.00     100.0\r\n",
        " 2014-05-08 06      18.02      1.86     16.16      89.7\r\n",
        " 2014-05-08 05      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-08 04      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-08 03      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-08 02      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-08 01      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-08 00      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 23      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 22      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 21      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 20      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 19      13.06      0.31     12.75      97.6\r\n",
        " 2014-05-07 18      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 17      13.41      0.31     13.10      97.7\r\n",
        " 2014-05-07 16      13.71      0.68     13.03      95.1\r\n",
        " 2014-05-07 15      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 14      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 13      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 12      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 11      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 10      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 09      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 08      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 07      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 06      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 05      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 04      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 03      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 02      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 01      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-07 00      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-06 23      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-06 22      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-06 21      13.06      0.00     13.06     100.0\r\n",
        " 2014-05-06 20       9.33      0.66      8.67      93.0\r\n",
        " 2014-05-06 19       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 18       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 17       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 16       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 15       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 14       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 13       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 12       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 11       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 10       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 09       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 08       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 07       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 06       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 05       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 04       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 03       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 02       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 01       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-06 00       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 23       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 22       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 21       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 20       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 19       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 18       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 17       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 16       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 15       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 14       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 13       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 12       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 11       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 10       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 09       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 08       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 07       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-05 06       8.35      0.00      8.35     100.0\r\n",
        " 2014-05-05 05      33.00      0.00     33.00     100.0\r\n",
        " 2014-05-05 04      33.00      0.00     33.00     100.0\r\n",
        " 2014-05-05 03      33.00      0.00     33.00     100.0\r\n",
        " 2014-05-05 02      33.00      0.00     33.00     100.0\r\n",
        " 2014-05-05 01      33.00      0.00     33.00     100.0\r\n",
        " 2014-05-05 00      33.00      0.00     33.00     100.0\r\n",
        " 2014-05-04 23      27.62      1.09     26.53      96.1\r\n",
        " 2014-05-04 22      14.00      0.00     14.00     100.0\r\n",
        " 2014-05-04 21      14.00      0.00     14.00     100.0\r\n",
        " 2014-05-04 20      11.03      0.69     10.34      93.8\r\n",
        " 2014-05-04 19       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-04 18       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-04 17       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-04 16       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-04 15       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-04 14       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-04 13       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-04 12       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-04 11       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-04 10       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-04 09       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-04 08       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-04 07       0.00      0.00      0.00       0.0\r\n",
        " 2014-05-04 06      14.38      0.00     14.38     100.0\r\n",
        " 2014-05-04 05       9.62      1.17      8.45      87.9\r\n",
        "\r\n",
        "* Job flows are considered to belong to the user and job that\r\n",
        "  started them or last ran on them.\r\n",
        "\r\n",
        "Top jobs, by total time used:\r\n",
        "      15.84 mr_weather\r\n",
        "       5.46 None\r\n",
        "       3.97 mr_word_freq_count\r\n",
        "       0.38 no_script\r\n",
        "\r\n",
        "Top jobs, by time billed but not used:\r\n",
        "    1051.88 None\r\n",
        "     286.85 mr_word_freq_count\r\n",
        "     253.22 mr_weather\r\n",
        "      44.49 no_script\r\n",
        "\r\n",
        "Top users, by total time used:\r\n",
        "      19.11 yoavfreund\r\n",
        "       5.46 None\r\n",
        "       1.08 ubuntu\r\n",
        "\r\n",
        "Top users, by time billed but not used:\r\n",
        "    1051.88 None\r\n",
        "     577.06 yoavfreund\r\n",
        "       7.49 ubuntu\r\n",
        "\r\n",
        "Top job steps, by total time used (step number first):\r\n",
        "      15.84   1 mr_weather\r\n",
        "       3.88   1 mr_word_freq_count\r\n",
        "       0.40     (non-mrjob step)\r\n",
        "\r\n",
        "Top job steps, by total time billed but not used (un-pooled only):\r\n",
        "    1051.92     (non-mrjob step)\r\n",
        "     286.85   1 mr_word_freq_count\r\n",
        "     253.22   1 mr_weather\r\n",
        "\r\n",
        "All pools, by total time billed:\r\n",
        "    1662.08 (not pooled)\r\n",
        "\r\n",
        "All pools, by total time billed but not used:\r\n",
        "    1636.43 (not pooled)\r\n",
        "\r\n",
        "All job flows, by total time billed:\r\n",
        "     560.00 j-35O01QLMRUFED My cluster\r\n",
        "     444.00 j-3MMGSXIO3FQR3 My cluster\r\n",
        "     358.08 j-1HFD8T7K9LGVH no_script.yoavfreund.20140509.131949.007708\r\n",
        "     231.00 j-19ZLC6D8RI1E4 My Bigger Cluster\r\n",
        "      42.00 j-KZSDWFOETODE  My Bigger Cluster\r\n",
        "      24.00 j-2DP66KPYB7NHE My Bigger Cluster\r\n",
        "       1.00 j-NXJGTL9EFM35  mr_word_freq_count.yoavfreund.20140507.161040.869606\r\n",
        "       1.00 j-1QCXB5Q0VHRB2 mr_word_freq_count.yoavfreund.20140508.141408.998481\r\n",
        "       1.00 j-3IR7VIA9RA2TH mr_word_freq_count.yoavfreund.20140509.003734.519811\r\n",
        "       0.00 j-A0JHEG86PAGJ  A 6 node spot market cluster\r\n",
        "       0.00 j-2M58Y9QSWOIFH A 6 node spot market cluster\r\n",
        "       0.00 j-13O1ZEWJ0595Q A 6 node spot market cluster\r\n",
        "       0.00 j-1BCZIG7KD2S0K My Bigger Cluster\r\n",
        "       0.00 j-6ZU44Z9AXTQ3  My Bigger Cluster\r\n",
        "       0.00 j-2E4BUM0ADD3MX My Bigger Cluster\r\n",
        "       0.00 j-3T3SHY8GBF6H4 no_script.yoavfreund.20140509.065034.068893\r\n",
        "       0.00 j-33FAYHWEI1FP  no_script.yoavfreund.20140509.065544.819488\r\n",
        "\r\n",
        "All job flows, by time billed but not used:\r\n",
        "     556.78 j-35O01QLMRUFED My cluster\r\n",
        "     442.11 j-3MMGSXIO3FQR3 My cluster\r\n",
        "     340.68 j-1HFD8T7K9LGVH no_script.yoavfreund.20140509.131949.007708\r\n",
        "     229.91 j-19ZLC6D8RI1E4 My Bigger Cluster\r\n",
        "      41.31 j-KZSDWFOETODE  My Bigger Cluster\r\n",
        "      22.83 j-2DP66KPYB7NHE My Bigger Cluster\r\n",
        "       0.94 j-3IR7VIA9RA2TH mr_word_freq_count.yoavfreund.20140509.003734.519811\r\n",
        "       0.94 j-NXJGTL9EFM35  mr_word_freq_count.yoavfreund.20140507.161040.869606\r\n",
        "       0.93 j-1QCXB5Q0VHRB2 mr_word_freq_count.yoavfreund.20140508.141408.998481\r\n",
        "       0.00 j-A0JHEG86PAGJ  A 6 node spot market cluster\r\n",
        "       0.00 j-2M58Y9QSWOIFH A 6 node spot market cluster\r\n",
        "       0.00 j-13O1ZEWJ0595Q A 6 node spot market cluster\r\n",
        "       0.00 j-1BCZIG7KD2S0K My Bigger Cluster\r\n",
        "       0.00 j-6ZU44Z9AXTQ3  My Bigger Cluster\r\n",
        "       0.00 j-2E4BUM0ADD3MX My Bigger Cluster\r\n",
        "       0.00 j-3T3SHY8GBF6H4 no_script.yoavfreund.20140509.065034.068893\r\n",
        "       0.00 j-33FAYHWEI1FP  no_script.yoavfreund.20140509.065544.819488\r\n",
        "\r\n",
        "Details for all job flows:\r\n",
        "\r\n",
        " id              state         created             steps        time ran     billed    waste   user   name\r\n",
        " j-1HFD8T7K9LGVH WAITING       2014-05-09 13:19:58  17          11:34:55     17.40    340.68 yoavfreund no_script\r\n",
        " j-33FAYHWEI1FP  TERMINATED    2014-05-09 06:55:53   0           0:00:00      0.00      0.00 yoavfreund no_script\r\n",
        " j-3T3SHY8GBF6H4 TERMINATED    2014-05-09 06:50:43   0           0:00:00      0.00      0.00 yoavfreund no_script\r\n",
        " j-3IR7VIA9RA2TH COMPLETED     2014-05-09 00:37:44   1           0:04:53      0.06      0.94 yoavfreund mr_word_freq_count\r\n",
        " j-1QCXB5Q0VHRB2 COMPLETED     2014-05-08 14:14:19   1           0:05:08      0.07      0.93 yoavfreund mr_word_freq_count\r\n",
        " j-35O01QLMRUFED TERMINATED    2014-05-08 06:19:21   3          19:34:35      3.22    556.78          not started by mrjob\r\n",
        " j-NXJGTL9EFM35  COMPLETED     2014-05-07 16:10:51   1           0:05:00      0.06      0.94 yoavfreund mr_word_freq_count\r\n",
        " j-A0JHEG86PAGJ  FAILED        2014-05-07 00:43:12   1           0:00:00      0.00      0.00          not started by mrjob\r\n",
        " j-3MMGSXIO3FQR3 TERMINATED    2014-05-06 20:14:11   5    1 day, 9:55:15      1.89    442.11          not started by mrjob\r\n",
        " j-2M58Y9QSWOIFH FAILED        2014-05-06 15:30:34   1           0:00:00      0.00      0.00          not started by mrjob\r\n",
        " j-13O1ZEWJ0595Q FAILED        2014-05-06 04:52:07   1           0:00:00      0.00      0.00          not started by mrjob\r\n",
        " j-1BCZIG7KD2S0K FAILED        2014-05-06 03:15:25   1           0:00:00      0.00      0.00          not started by mrjob\r\n",
        " j-6ZU44Z9AXTQ3  FAILED        2014-05-06 00:29:50   1           0:00:00      0.00      0.00          not started by mrjob\r\n",
        " j-2E4BUM0ADD3MX FAILED        2014-05-06 00:10:53   1           0:00:00      0.00      0.00          not started by mrjob\r\n",
        " j-19ZLC6D8RI1E4 TERMINATED    2014-05-04 23:12:39   1           6:20:55      1.09    229.91          not started by mrjob\r\n",
        " j-KZSDWFOETODE  TERMINATED    2014-05-04 20:09:33   1           2:45:09      0.69     41.31          not started by mrjob\r\n",
        " j-2DP66KPYB7NHE TERMINATED    2014-05-04 05:33:15   1           0:19:44      1.17     22.83          not started by mrjob\r\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "s3cmd is a utility that makes it easy to work with s3"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!s3cmd --help"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Usage: s3cmd [options] COMMAND [parameters]\r\n",
        "\r\n",
        "S3cmd is a tool for managing objects in Amazon S3 storage. It allows for\r\n",
        "making and removing \"buckets\" and uploading, downloading and removing\r\n",
        "\"objects\" from these buckets.\r\n",
        "\r\n",
        "Options:\r\n",
        "  -h, --help            show this help message and exit\r\n",
        "  --configure           Invoke interactive (re)configuration tool.\r\n",
        "  -c FILE, --config=FILE\r\n",
        "                        Config file name. Defaults to /home/ubuntu/.s3cfg\r\n",
        "  --dump-config         Dump current configuration after parsing config files\r\n",
        "                        and command line options and exit.\r\n",
        "  -n, --dry-run         Only show what should be uploaded or downloaded but\r\n",
        "                        don't actually do it. May still perform S3 requests to\r\n",
        "                        get bucket listings and other information though (only\r\n",
        "                        for file transfer commands)\r\n",
        "  -e, --encrypt         Encrypt files before uploading to S3.\r\n",
        "  --no-encrypt          Don't encrypt files.\r\n",
        "  -f, --force           Force overwrite and other dangerous operations.\r\n",
        "  --continue            Continue getting a partially downloaded file (only for\r\n",
        "                        [get] command).\r\n",
        "  --skip-existing       Skip over files that exist at the destination (only\r\n",
        "                        for [get] and [sync] commands).\r\n",
        "  -r, --recursive       Recursive upload, download or removal.\r\n",
        "  --check-md5           Check MD5 sums when comparing files for [sync].\r\n",
        "                        (default)\r\n",
        "  --no-check-md5        Do not check MD5 sums when comparing files for [sync].\r\n",
        "                        Only size will be compared. May significantly speed up\r\n",
        "                        transfer but may also miss some changed files.\r\n",
        "  -P, --acl-public      Store objects with ACL allowing read for anyone.\r\n",
        "  --acl-private         Store objects with default ACL allowing access for you\r\n",
        "                        only.\r\n",
        "  --acl-grant=PERMISSION:EMAIL or USER_CANONICAL_ID\r\n",
        "                        Grant stated permission to a given amazon user.\r\n",
        "                        Permission is one of: read, write, read_acp,\r\n",
        "                        write_acp, full_control, all\r\n",
        "  --acl-revoke=PERMISSION:USER_CANONICAL_ID\r\n",
        "                        Revoke stated permission for a given amazon user.\r\n",
        "                        Permission is one of: read, write, read_acp, wr\r\n",
        "                        ite_acp, full_control, all\r\n",
        "  --delete-removed      Delete remote objects with no corresponding local file\r\n",
        "                        [sync]\r\n",
        "  --no-delete-removed   Don't delete remote objects.\r\n",
        "  -p, --preserve        Preserve filesystem attributes (mode, ownership,\r\n",
        "                        timestamps). Default for [sync] command.\r\n",
        "  --no-preserve         Don't store FS attributes\r\n",
        "  --exclude=GLOB        Filenames and paths matching GLOB will be excluded\r\n",
        "                        from sync\r\n",
        "  --exclude-from=FILE   Read --exclude GLOBs from FILE\r\n",
        "  --rexclude=REGEXP     Filenames and paths matching REGEXP (regular\r\n",
        "                        expression) will be excluded from sync\r\n",
        "  --rexclude-from=FILE  Read --rexclude REGEXPs from FILE\r\n",
        "  --include=GLOB        Filenames and paths matching GLOB will be included\r\n",
        "                        even if previously excluded by one of\r\n",
        "                        --(r)exclude(-from) patterns\r\n",
        "  --include-from=FILE   Read --include GLOBs from FILE\r\n",
        "  --rinclude=REGEXP     Same as --include but uses REGEXP (regular expression)\r\n",
        "                        instead of GLOB\r\n",
        "  --rinclude-from=FILE  Read --rinclude REGEXPs from FILE\r\n",
        "  --bucket-location=BUCKET_LOCATION\r\n",
        "                        Datacentre to create bucket in. As of now the\r\n",
        "                        datacenters are: US (default), EU, us-west-1, and ap-\r\n",
        "                        southeast-1\r\n",
        "  --reduced-redundancy, --rr\r\n",
        "                        Store object with 'Reduced redundancy'. Lower per-GB\r\n",
        "                        price. [put, cp, mv]\r\n",
        "  --access-logging-target-prefix=LOG_TARGET_PREFIX\r\n",
        "                        Target prefix for access logs (S3 URI) (for [cfmodify]\r\n",
        "                        and [accesslog] commands)\r\n",
        "  --no-access-logging   Disable access logging (for [cfmodify] and [accesslog]\r\n",
        "                        commands)\r\n",
        "  -m MIME/TYPE, --mime-type=MIME/TYPE\r\n",
        "                        Default MIME-type to be set for objects stored.\r\n",
        "  -M, --guess-mime-type\r\n",
        "                        Guess MIME-type of files by their extension. Falls\r\n",
        "                        back to default MIME-Type as specified by --mime-type\r\n",
        "                        option\r\n",
        "  --add-header=NAME:VALUE\r\n",
        "                        Add a given HTTP header to the upload request. Can be\r\n",
        "                        used multiple times. For instance set 'Expires' or\r\n",
        "                        'Cache-Control' headers (or both) using this options\r\n",
        "                        if you like.\r\n",
        "  --encoding=ENCODING   Override autodetected terminal and filesystem encoding\r\n",
        "                        (character set). Autodetected: UTF-8\r\n",
        "  --verbatim            Use the S3 name as given on the command line. No pre-\r\n",
        "                        processing, encoding, etc. Use with caution!\r\n",
        "  --list-md5            Include MD5 sums in bucket listings (only for 'ls'\r\n",
        "                        command).\r\n",
        "  -H, --human-readable-sizes\r\n",
        "                        Print sizes in human readable form (eg 1kB instead of\r\n",
        "                        1234).\r\n",
        "  --progress            Display progress meter (default on TTY).\r\n",
        "  --no-progress         Don't display progress meter (default on non-TTY).\r\n",
        "  --enable              Enable given CloudFront distribution (only for\r\n",
        "                        [cfmodify] command)\r\n",
        "  --disable             Enable given CloudFront distribution (only for\r\n",
        "                        [cfmodify] command)\r\n",
        "  --cf-add-cname=CNAME  Add given CNAME to a CloudFront distribution (only for\r\n",
        "                        [cfcreate] and [cfmodify] commands)\r\n",
        "  --cf-remove-cname=CNAME\r\n",
        "                        Remove given CNAME from a CloudFront distribution\r\n",
        "                        (only for [cfmodify] command)\r\n",
        "  --cf-comment=COMMENT  Set COMMENT for a given CloudFront distribution (only\r\n",
        "                        for [cfcreate] and [cfmodify] commands)\r\n",
        "  --cf-default-root-object=DEFAULT_ROOT_OBJECT\r\n",
        "                        Set the default root object to return when no object\r\n",
        "                        is specified in the URL. Use a relative path, i.e.\r\n",
        "                        default/index.html instead of /default/index.html or\r\n",
        "                        s3://bucket/default/index.html (only for [cfcreate]\r\n",
        "                        and [cfmodify] commands)\r\n",
        "  -v, --verbose         Enable verbose output.\r\n",
        "  -d, --debug           Enable debug output.\r\n",
        "  --version             Show s3cmd version (1.0.0) and exit.\r\n",
        "  -F, --follow-symlinks\r\n",
        "                        Follow symbolic links as if they are regular files\r\n",
        "\r\n",
        "Commands:\r\n",
        "  Make bucket\r\n",
        "      s3cmd mb s3://BUCKET\r\n",
        "  Remove bucket\r\n",
        "      s3cmd rb s3://BUCKET\r\n",
        "  List objects or buckets\r\n",
        "      s3cmd ls [s3://BUCKET[/PREFIX]]\r\n",
        "  List all object in all buckets\r\n",
        "      s3cmd la \r\n",
        "  Put file into bucket\r\n",
        "      s3cmd put FILE [FILE...] s3://BUCKET[/PREFIX]\r\n",
        "  Get file from bucket\r\n",
        "      s3cmd get s3://BUCKET/OBJECT LOCAL_FILE\r\n",
        "  Delete file from bucket\r\n",
        "      s3cmd del s3://BUCKET/OBJECT\r\n",
        "  Synchronize a directory tree to S3\r\n",
        "      s3cmd sync LOCAL_DIR s3://BUCKET[/PREFIX] or s3://BUCKET[/PREFIX] LOCAL_DIR\r\n",
        "  Disk usage by buckets\r\n",
        "      s3cmd du [s3://BUCKET[/PREFIX]]\r\n",
        "  Get various information about Buckets or Files\r\n",
        "      s3cmd info s3://BUCKET[/OBJECT]\r\n",
        "  Copy object\r\n",
        "      s3cmd cp s3://BUCKET1/OBJECT1 s3://BUCKET2[/OBJECT2]\r\n",
        "  Move object\r\n",
        "      s3cmd mv s3://BUCKET1/OBJECT1 s3://BUCKET2[/OBJECT2]\r\n",
        "  Modify Access control list for Bucket or Files\r\n",
        "      s3cmd setacl s3://BUCKET[/OBJECT]\r\n",
        "  Enable/disable bucket access logging\r\n",
        "      s3cmd accesslog s3://BUCKET\r\n",
        "  Sign arbitrary string using the secret key\r\n",
        "      s3cmd sign STRING-TO-SIGN\r\n",
        "  Fix invalid file names in a bucket\r\n",
        "      s3cmd fixbucket s3://BUCKET[/PREFIX]\r\n",
        "  List CloudFront distribution points\r\n",
        "      s3cmd cflist \r\n",
        "  Display CloudFront distribution point parameters\r\n",
        "      s3cmd cfinfo [cf://DIST_ID]\r\n",
        "  Create CloudFront distribution point\r\n",
        "      s3cmd cfcreate s3://BUCKET\r\n",
        "  Delete CloudFront distribution point\r\n",
        "      s3cmd cfdelete cf://DIST_ID\r\n",
        "  Change CloudFront distribution point parameters\r\n",
        "      s3cmd cfmodify cf://DIST_ID\r\n",
        "\r\n",
        "For more informations see the progect homepage:\r\n",
        "http://s3tools.org\r\n",
        "\r\n",
        "Consider a donation if you have found s3cmd useful:\r\n",
        "http://s3tools.org/donate\r\n",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load /home/ubuntu/UCSD_BigData/utils/AWS_keypair_management.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile /home/ubuntu/UCSD_BigData/utils/AWS_keypair_management.py\n",
      "from glob import glob\n",
      "from string import strip\n",
      "from os import chdir\n",
      "from mrjob.emr import EMRJobRunner\n",
      "\n",
      "def test_key_pair(Access_Key_Id,Secret_Access_Key):\n",
      "    try:\n",
      "        JobRunner = EMRJobRunner(aws_access_key_id=Access_Key_Id,aws_secret_access_key=Secret_Access_Key)\n",
      "        return True\n",
      "    except:\n",
      "        return False\n",
      "    \n",
      "def Get_Working_Credentials(path):\n",
      "    \"\"\" check all files in the path directory, find the files that \n",
      "    contain key-pairs in the format downloaded from AWS and check which\n",
      "    of these AWS key pairs is active.\n",
      "    \"\"\"\n",
      "    chdir(path)\n",
      "    credentials_header='User Name,Access Key Id,Secret Access Key'\n",
      "    Key_Table={}\n",
      "    bad_key_files=[]\n",
      "    for filename in glob('*'):\n",
      "        with open(filename,'r') as file:\n",
      "            header_line=strip(file.readline())\n",
      "            if header_line==credentials_header:\n",
      "                # print '\"%s\"'%header_line\n",
      "                for line in file.readlines():\n",
      "                    (User_Name,Access_Key_Id,Secret_Access_Key)=strip(line).split(',')\n",
      "                    User_Name=User_Name[1:-1]\n",
      "                    print filename,User_Name,Access_Key_Id,Secret_Access_Key\n",
      "                    if test_key_pair(Access_Key_Id,Secret_Access_Key):\n",
      "                        print \"an active key pair\"\n",
      "                        if not Access_Key_Id in Key_Table.keys():\n",
      "                            Key_Table[Access_Key_Id]=[]\n",
      "                        Key_Table[Access_Key_Id].append({\n",
      "                            'Access_Key_Id':Access_Key_Id,'Secret_Access_Key':Secret_Access_Key})\n",
      "                    else:\n",
      "                        print filename,\"an inactive key pair\"\n",
      "                        bad_key_files.append(filename)\n",
      "    return Key_Table,bad_key_files\n",
      "#Get_Working_Credentials('../../Vault/')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting /home/ubuntu/UCSD_BigData/utils/AWS_keypair_management.py\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}